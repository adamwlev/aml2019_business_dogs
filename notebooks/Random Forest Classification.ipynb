{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "def lower(word):\n",
    "    return word.lower()\n",
    "\n",
    "lemm = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize(word):\n",
    "    return lemm.lemmatize(word)\n",
    "\n",
    "punct = set(string.punctuation)\n",
    "def no_punctuation(word):\n",
    "    return ''.join(c for c in word if c not in punct)\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "def no_stop_words(word):\n",
    "    return word if word not in stop_words else ''\n",
    "\n",
    "strategy_map = {'lo':lower,'lem':lemmatize,\n",
    "                'punct':no_punctuation,'stop':no_stop_words}\n",
    "\n",
    "def preprocess(docs,strategies):\n",
    "    for strategy in strategies:\n",
    "        new_docs = []\n",
    "        for doc in docs:\n",
    "            new_doc = []\n",
    "            for word in doc:\n",
    "                transformed = strategy_map[strategy](word)\n",
    "                if transformed:\n",
    "                    new_doc.append(transformed)\n",
    "            new_docs.append(new_doc)\n",
    "        docs = new_docs\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_train = []\n",
    "for i in range(10000):\n",
    "    with open('../descriptions_train/%d.txt' % (i,)) as f:\n",
    "        documents_train.append(f.read().split())\n",
    "documents_train = preprocess(documents_train,['lo','punct'])\n",
    "documents_train_new = []\n",
    "for i in range(10000):\n",
    "    documents_train_new.append(TaggedDocument(documents_train[i],[i]))\n",
    "documents_train = documents_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents_train, vector_size=100, window=10, \n",
    "                min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(documents_train,total_examples=model.corpus_count,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['two', 'giraffes', 'in', 'a', 'room', 'with', 'people', 'looking', 'at', 'them', 'two', 'giraffe', 'standing', 'next', 'to', 'each', 'other', 'in', 'a', 'room', 'the', 'giraffe', 'is', 'being', 'kept', 'by', 'itself', 'indoors', 'a', 'man', 'and', 'woman', 'staring', 'at', 'two', 'giraffes', 'through', 'a', 'window', 'a', 'giraffe', 'in', 'a', 'enclosed', 'area', 'is', 'watched', 'by', 'some', 'people'], tags=[44])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_train[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.5827369689941406),\n",
       " ('man', 0.5552079081535339),\n",
       " ('child', 0.5540258288383484),\n",
       " ('person', 0.5419774055480957),\n",
       " ('dogs', 0.5106233358383179),\n",
       " ('sheep', 0.5050454139709473),\n",
       " ('house', 0.5029844045639038),\n",
       " ('boy', 0.49989622831344604),\n",
       " ('doughnut', 0.49748361110687256),\n",
       " ('hotdog', 0.4972448945045471),\n",
       " ('snowboard', 0.4694925546646118),\n",
       " ('surfboard', 0.4642629027366638)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"dog\",topn=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = np.array([model[i] for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = np.zeros((2000,text_train.shape[1]))\n",
    "documents_test = []\n",
    "for i in range(2000):\n",
    "    with open('../descriptions_test/%d.txt' % (i,)) as f:\n",
    "        documents_test.append(f.read().split())\n",
    "documents_test = preprocess(documents_test,['lo','punct'])\n",
    "for i in range(2000):\n",
    "    text_test[i] = model.infer_vector(documents_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = np.hstack([text_train,np.ones((10000,1))])\n",
    "text_test = np.hstack([text_test,np.ones((2000,1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 101), (2000, 101))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape,text_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_train = pd.read_csv('../features_train/features_resnet1000intermediate_train.csv',header=None)\n",
    "feats_train_b = pd.read_csv('../features_train/features_resnet1000_train.csv',header=None)\n",
    "feats_test = pd.read_csv('../features_test/features_resnet1000intermediate_test.csv',header=None)\n",
    "feats_test_b = pd.read_csv('../features_test/features_resnet1000_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images_train/5373.jpg</td>\n",
       "      <td>-0.899450</td>\n",
       "      <td>-0.930470</td>\n",
       "      <td>-2.503365</td>\n",
       "      <td>-3.172499</td>\n",
       "      <td>-2.819133</td>\n",
       "      <td>0.992159</td>\n",
       "      <td>-3.698863</td>\n",
       "      <td>0.619991</td>\n",
       "      <td>0.956148</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.021916</td>\n",
       "      <td>2.214253</td>\n",
       "      <td>-1.382491</td>\n",
       "      <td>1.672911</td>\n",
       "      <td>1.014233</td>\n",
       "      <td>2.599949</td>\n",
       "      <td>2.773284</td>\n",
       "      <td>-2.066632</td>\n",
       "      <td>0.385754</td>\n",
       "      <td>-3.241320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images_train/984.jpg</td>\n",
       "      <td>-1.346954</td>\n",
       "      <td>-3.119461</td>\n",
       "      <td>-0.765971</td>\n",
       "      <td>-1.382550</td>\n",
       "      <td>-1.104675</td>\n",
       "      <td>-3.656271</td>\n",
       "      <td>-4.815436</td>\n",
       "      <td>-0.556942</td>\n",
       "      <td>-1.402286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>-3.968805</td>\n",
       "      <td>-2.694711</td>\n",
       "      <td>-4.196480</td>\n",
       "      <td>-2.880234</td>\n",
       "      <td>-1.210742</td>\n",
       "      <td>-1.605143</td>\n",
       "      <td>-4.859987</td>\n",
       "      <td>-0.837670</td>\n",
       "      <td>-0.967604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images_train/7127.jpg</td>\n",
       "      <td>-3.445498</td>\n",
       "      <td>-1.524573</td>\n",
       "      <td>-1.001654</td>\n",
       "      <td>-3.668335</td>\n",
       "      <td>-1.805517</td>\n",
       "      <td>-1.633496</td>\n",
       "      <td>-7.127826</td>\n",
       "      <td>-1.147802</td>\n",
       "      <td>-1.055816</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.991777</td>\n",
       "      <td>-2.628053</td>\n",
       "      <td>-2.971074</td>\n",
       "      <td>-2.537039</td>\n",
       "      <td>-1.707429</td>\n",
       "      <td>1.013672</td>\n",
       "      <td>0.608460</td>\n",
       "      <td>-3.714998</td>\n",
       "      <td>-0.484735</td>\n",
       "      <td>0.138767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images_train/9609.jpg</td>\n",
       "      <td>1.114650</td>\n",
       "      <td>-2.167102</td>\n",
       "      <td>0.097881</td>\n",
       "      <td>-1.336255</td>\n",
       "      <td>0.853483</td>\n",
       "      <td>-0.374885</td>\n",
       "      <td>-2.369090</td>\n",
       "      <td>-2.273191</td>\n",
       "      <td>-1.143788</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.248134</td>\n",
       "      <td>-0.633126</td>\n",
       "      <td>-1.723514</td>\n",
       "      <td>-2.638832</td>\n",
       "      <td>0.097149</td>\n",
       "      <td>4.647974</td>\n",
       "      <td>1.030138</td>\n",
       "      <td>-2.193836</td>\n",
       "      <td>1.044024</td>\n",
       "      <td>0.176043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images_train/5293.jpg</td>\n",
       "      <td>1.602650</td>\n",
       "      <td>-1.505817</td>\n",
       "      <td>3.029409</td>\n",
       "      <td>4.092412</td>\n",
       "      <td>1.711755</td>\n",
       "      <td>6.271253</td>\n",
       "      <td>4.173686</td>\n",
       "      <td>-2.177313</td>\n",
       "      <td>0.747789</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.285806</td>\n",
       "      <td>-2.266481</td>\n",
       "      <td>-3.898053</td>\n",
       "      <td>2.295787</td>\n",
       "      <td>-1.749552</td>\n",
       "      <td>0.974188</td>\n",
       "      <td>1.258117</td>\n",
       "      <td>-1.975622</td>\n",
       "      <td>-1.278643</td>\n",
       "      <td>-1.941441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5     \\\n",
       "0  images_train/5373.jpg -0.899450 -0.930470 -2.503365 -3.172499 -2.819133   \n",
       "1   images_train/984.jpg -1.346954 -3.119461 -0.765971 -1.382550 -1.104675   \n",
       "2  images_train/7127.jpg -3.445498 -1.524573 -1.001654 -3.668335 -1.805517   \n",
       "3  images_train/9609.jpg  1.114650 -2.167102  0.097881 -1.336255  0.853483   \n",
       "4  images_train/5293.jpg  1.602650 -1.505817  3.029409  4.092412  1.711755   \n",
       "\n",
       "       6         7         8         9     ...      991       992       993   \\\n",
       "0  0.992159 -3.698863  0.619991  0.956148  ... -3.021916  2.214253 -1.382491   \n",
       "1 -3.656271 -4.815436 -0.556942 -1.402286  ...  0.011003 -3.968805 -2.694711   \n",
       "2 -1.633496 -7.127826 -1.147802 -1.055816  ... -2.991777 -2.628053 -2.971074   \n",
       "3 -0.374885 -2.369090 -2.273191 -1.143788  ... -1.248134 -0.633126 -1.723514   \n",
       "4  6.271253  4.173686 -2.177313  0.747789  ... -1.285806 -2.266481 -3.898053   \n",
       "\n",
       "       994       995       996       997       998       999       1000  \n",
       "0  1.672911  1.014233  2.599949  2.773284 -2.066632  0.385754 -3.241320  \n",
       "1 -4.196480 -2.880234 -1.210742 -1.605143 -4.859987 -0.837670 -0.967604  \n",
       "2 -2.537039 -1.707429  1.013672  0.608460 -3.714998 -0.484735  0.138767  \n",
       "3 -2.638832  0.097149  4.647974  1.030138 -2.193836  1.044024  0.176043  \n",
       "4  2.295787 -1.749552  0.974188  1.258117 -1.975622 -1.278643 -1.941441  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_train_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2049), (2000, 2049))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_train.shape,feats_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train = np.zeros((10000,3048))\n",
    "for _,row in feats_train.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_train[i,:2048] = row.values[1:]\n",
    "for _,row in feats_train_b.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_train[i,2048:] = row.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3048.000000\n",
       "mean        0.286300\n",
       "std         0.726504\n",
       "min        -3.890733\n",
       "25%         0.259784\n",
       "50%         0.384236\n",
       "75%         0.526699\n",
       "max         4.441978\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pics_train.mean(0)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_test = np.zeros((2000,3048))\n",
    "for _,row in feats_test.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_test[i,:2048] = row.values[1:]\n",
    "for _,row in feats_test_b.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_test[i,2048:] = row.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3048.000000\n",
       "mean        0.286300\n",
       "std         0.726504\n",
       "min        -3.890733\n",
       "25%         0.259784\n",
       "50%         0.384236\n",
       "75%         0.526699\n",
       "max         4.441978\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pics_train.mean(0)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train = np.zeros((10000,100))\n",
    "tags_test = np.zeros((2000,100))\n",
    "tag_docs_train, tag_docs_test = [], []\n",
    "for i in range(10000):\n",
    "    with open('../tags_train/%d.txt' % (i,),'r') as f:\n",
    "        tag_docs_train.append([word for line in f.read().split('\\n') for word in line.split(':') if word])\n",
    "for i in range(2000):\n",
    "    with open('../tags_test/%d.txt' % (i,),'r') as f:\n",
    "        tag_docs_test.append([word for line in f.read().split('\\n') for word in line.split(':') if word])\n",
    "tag_docs_train = preprocess(tag_docs_train,['lo','punct'])\n",
    "tag_docs_test = preprocess(tag_docs_test,['lo','punct'])\n",
    "for i in range(10000):\n",
    "    tags_train[i] = model.infer_vector(tag_docs_train[i])\n",
    "for i in range(2000):\n",
    "    tags_test[i] = model.infer_vector(tag_docs_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2000.000000\n",
       "mean        0.072021\n",
       "std         0.067333\n",
       "min         0.000013\n",
       "25%         0.022011\n",
       "50%         0.053870\n",
       "75%         0.101180\n",
       "max         0.450649\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.abs(tags_test.mean(1))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train = np.hstack([pics_train,tags_train])\n",
    "pics_test = np.hstack([pics_test,tags_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=101)\n",
    "# pca.fit(pics_train)\n",
    "# pics_train = pca.transform(pics_train)\n",
    "# pics_test = pca.transform(pics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vecs,pics):\n",
    "    dists = pairwise_distances(vecs,pics,metric='cosine')\n",
    "    return dists.argsort(1)#[:,:20]\n",
    "\n",
    "def get_top_20(descr_id):\n",
    "    return preds[descr_id][:20]\n",
    "\n",
    "def save_submission():\n",
    "    data = []\n",
    "    for i in range(2000):\n",
    "        data.append(['%d.txt' % (i,),' '.join('%d.jpg' % (pic_id,) for pic_id in get_top_20(i))])\n",
    "    pd.DataFrame(data,columns=['Descritpion_ID','Top_20_Image_IDs']).to_csv('submission.csv',index=False)\n",
    "    \n",
    "def map_20(preds):\n",
    "    ranks = [np.argwhere(vec==i)[0][0] for i,vec in enumerate(preds)]\n",
    "    return np.mean([(20-rank)/20 if rank<20 else 0 for rank in ranks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('text_train_full',text_train)\n",
    "# np.save('pics_train_full',pics_train)\n",
    "text_train = np.load('text_train_full.npy')\n",
    "pics_train = np.load('pics_train_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 101), (10000, 3148))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape,pics_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50,max_depth=15,n_jobs=4,max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12609"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 3900)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((15000,3249))\n",
    "y = np.zeros((15000,1))\n",
    "for i in range(10000):\n",
    "    X[i] = np.concatenate([text_train[i],pics_train[i]])\n",
    "    y[i] = 1\n",
    "\n",
    "seen = set([])\n",
    "for i in range(10000,15000):\n",
    "    a,b = np.random.randint(0,10000,size=2)\n",
    "    while a==b or (a,b) in seen:\n",
    "        a,b = np.random.randint(0,10000,size=2)\n",
    "    X[i] = np.concatenate([text_train[a],pics_train[b]])\n",
    "    y[i] = 0\n",
    "    seen.add((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 3249), (15000, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-275a522f1167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprobs_negative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprobs_negative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlftw/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlftw/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlftw/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlftw/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlftw/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlftw/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amlftw/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y = np.ravel(y)\n",
    "cv = StratifiedKFold(n_splits=6,shuffle=True)\n",
    "probs_negative, probs_positive = [], []\n",
    "for train_index,test_index in cv.split(X,y):\n",
    "    rfc.fit(X[train_index],y[train_index])\n",
    "    preds = rfc.predict_proba(X[test_index])\n",
    "    probs_negative.extend(np.ravel(preds[y[test_index]==0][:,1]).tolist())\n",
    "    probs_positive.extend(np.ravel(preds[y[test_index]==1][:,1]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6741185637375107, 0.6661652977058632)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(probs_negative),np.mean(probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = rfc.estimators_[0].tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82695159, 0.17304841],\n",
       "       [0.83706945, 0.16293055],\n",
       "       [0.80336708, 0.19663292],\n",
       "       ...,\n",
       "       [0.78551618, 0.21448382],\n",
       "       [0.85234898, 0.14765102],\n",
       "       [0.77499846, 0.22500154]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8266150193809242,\n",
       " 0.17338498061907592,\n",
       " 0.7990812083380462,\n",
       " 0.20091879166195412,\n",
       " 0.8108351458682472,\n",
       " 0.18916485413175285,\n",
       " 0.8015126550092682,\n",
       " 0.19848734499073178,\n",
       " 0.7587363641019789,\n",
       " 0.2412636358980208,\n",
       " 0.8033884127314,\n",
       " 0.19661158726859976,\n",
       " 0.818692046025957,\n",
       " 0.18130795397404312,\n",
       " 0.7896820307005659,\n",
       " 0.2103179692994345,\n",
       " 0.7897180571209003,\n",
       " 0.21028194287909965,\n",
       " 0.7583644895754235,\n",
       " 0.24163551042457632,\n",
       " 0.7898278920214216,\n",
       " 0.21017210797857863,\n",
       " 0.776627601426133,\n",
       " 0.22337239857386704,\n",
       " 0.8243466874543186,\n",
       " 0.17565331254568137,\n",
       " 0.7758914737967808,\n",
       " 0.22410852620321922,\n",
       " 0.8069450651834695,\n",
       " 0.19305493481653088,\n",
       " 0.7685030854518716,\n",
       " 0.23149691454812843,\n",
       " 0.794979370592475,\n",
       " 0.2050206294075253,\n",
       " 0.8010626104301322,\n",
       " 0.198937389569868,\n",
       " 0.8247106524302183,\n",
       " 0.17528934756978162,\n",
       " 0.8229274792245951,\n",
       " 0.177072520775405,\n",
       " 0.8420014904647739,\n",
       " 0.15799850953522562,\n",
       " 0.7892829738034313,\n",
       " 0.21071702619656907,\n",
       " 0.7437816160185665,\n",
       " 0.25621838398143343,\n",
       " 0.7797751855990542,\n",
       " 0.22022481440094566,\n",
       " 0.826705876680768,\n",
       " 0.1732941233192317,\n",
       " 0.8125620820030857,\n",
       " 0.18743791799691462,\n",
       " 0.8189420444374059,\n",
       " 0.18105795556259408,\n",
       " 0.8199626725553759,\n",
       " 0.18003732744462378,\n",
       " 0.7948733154593812,\n",
       " 0.2051266845406188,\n",
       " 0.8125006248448993,\n",
       " 0.1874993751551009,\n",
       " 0.6973317399245689,\n",
       " 0.3026682600754313,\n",
       " 0.8066051073799022,\n",
       " 0.193394892620098,\n",
       " 0.7933349986870492,\n",
       " 0.20666500131295085,\n",
       " 0.7779672360368525,\n",
       " 0.2220327639631477,\n",
       " 0.8030020036398118,\n",
       " 0.19699799636018867,\n",
       " 0.7879927055250812,\n",
       " 0.2120072944749186,\n",
       " 0.8297278564657782,\n",
       " 0.17027214353422196,\n",
       " 0.8307933289364113,\n",
       " 0.16920667106358891,\n",
       " 0.7904260187094594,\n",
       " 0.20957398129054097,\n",
       " 0.7969854062808941,\n",
       " 0.20301459371910652,\n",
       " 0.8189458066962595,\n",
       " 0.18105419330374062,\n",
       " 0.8101079300905758,\n",
       " 0.18989206990942417,\n",
       " 0.808999210333163,\n",
       " 0.191000789666837,\n",
       " 0.8010634014637428,\n",
       " 0.19893659853625725,\n",
       " 0.7973785879547209,\n",
       " 0.20262141204527914,\n",
       " 0.8313068555996854,\n",
       " 0.1686931444003146,\n",
       " 0.8028241779882359,\n",
       " 0.19717582201176426,\n",
       " 0.8208677274911328,\n",
       " 0.17913227250886732,\n",
       " 0.8025628074451809,\n",
       " 0.19743719255481954,\n",
       " 0.813633885091652,\n",
       " 0.18636611490834798,\n",
       " 0.8173405968366448,\n",
       " 0.18265940316335502,\n",
       " 0.8078395033188037,\n",
       " 0.19216049668119647,\n",
       " 0.8084726641989286,\n",
       " 0.19152733580107142,\n",
       " 0.8121517724648666,\n",
       " 0.18784822753513353,\n",
       " 0.7994441346301882,\n",
       " 0.20055586536981224,\n",
       " 0.8254183060711123,\n",
       " 0.17458169392888748,\n",
       " 0.8343003093695756,\n",
       " 0.16569969063042472,\n",
       " 0.7898916509407576,\n",
       " 0.21010834905924256,\n",
       " 0.7778631012229136,\n",
       " 0.22213689877708692,\n",
       " 0.8288083798191339,\n",
       " 0.17119162018086664,\n",
       " 0.7502117033957305,\n",
       " 0.2497882966042698,\n",
       " 0.820392152473541,\n",
       " 0.17960784752645903,\n",
       " 0.7888597712770832,\n",
       " 0.21114022872291652,\n",
       " 0.8377654701960909,\n",
       " 0.16223452980390904,\n",
       " 0.8157373085343855,\n",
       " 0.18426269146561466,\n",
       " 0.819538348867309,\n",
       " 0.18046165113269116,\n",
       " 0.8090108615737663,\n",
       " 0.19098913842623344,\n",
       " 0.7822782307126142,\n",
       " 0.21772176928738612,\n",
       " 0.8245853803593575,\n",
       " 0.17541461964064267,\n",
       " 0.746698162761351,\n",
       " 0.2533018372386491,\n",
       " 0.8110131495484318,\n",
       " 0.188986850451568,\n",
       " 0.7678598846033273,\n",
       " 0.23214011539667265,\n",
       " 0.7526459559637082,\n",
       " 0.24735404403629196,\n",
       " 0.8014044009168656,\n",
       " 0.1985955990831345,\n",
       " 0.8335064523785889,\n",
       " 0.16649354762141136,\n",
       " 0.7757452357873853,\n",
       " 0.22425476421261467,\n",
       " 0.8015890550660332,\n",
       " 0.19841094493396694,\n",
       " 0.8328442026687912,\n",
       " 0.16715579733120867,\n",
       " 0.8003550399461246,\n",
       " 0.19964496005387564,\n",
       " 0.7460288477909299,\n",
       " 0.2539711522090701,\n",
       " 0.7592175006151877,\n",
       " 0.24078249938481233,\n",
       " 0.8345742190391126,\n",
       " 0.16542578096088792,\n",
       " 0.7756187105163364,\n",
       " 0.2243812894836637,\n",
       " 0.7883626763108924,\n",
       " 0.2116373236891075,\n",
       " 0.7781296054735358,\n",
       " 0.2218703945264641,\n",
       " 0.777230774152843,\n",
       " 0.22276922584715705,\n",
       " 0.7811009087394288,\n",
       " 0.21889909126057105,\n",
       " 0.7944245318964982,\n",
       " 0.20557546810350172,\n",
       " 0.8009006942967328,\n",
       " 0.19909930570326725,\n",
       " 0.7849905192063618,\n",
       " 0.21500948079363805,\n",
       " 0.8001680308847966,\n",
       " 0.1998319691152037,\n",
       " 0.8430614426471231,\n",
       " 0.15693855735287676,\n",
       " 0.8154655510546879,\n",
       " 0.1845344489453122,\n",
       " 0.8066645772249401,\n",
       " 0.19333542277505977,\n",
       " 0.7268649999406245,\n",
       " 0.27313500005937563,\n",
       " 0.7889266399232217,\n",
       " 0.2110733600767783,\n",
       " 0.8255098444213487,\n",
       " 0.17449015557865136,\n",
       " 0.8280004159400857,\n",
       " 0.171999584059914,\n",
       " 0.806623006072321,\n",
       " 0.19337699392767935,\n",
       " 0.8434953458392452,\n",
       " 0.15650465416075474,\n",
       " 0.778473759448007,\n",
       " 0.22152624055199296,\n",
       " 0.8062906846970722,\n",
       " 0.19370931530292765,\n",
       " 0.8193250882419992,\n",
       " 0.18067491175800046,\n",
       " 0.7652601890968777,\n",
       " 0.2347398109031226,\n",
       " 0.8094870957684457,\n",
       " 0.19051290423155437,\n",
       " 0.7694171355752072,\n",
       " 0.23058286442479323,\n",
       " 0.8126931709528055,\n",
       " 0.18730682904719476,\n",
       " 0.788506013733298,\n",
       " 0.21149398626670193,\n",
       " 0.8082042621378993,\n",
       " 0.1917957378621005,\n",
       " 0.7663684717762035,\n",
       " 0.2336315282237968,\n",
       " 0.7713816226421741,\n",
       " 0.22861837735782584,\n",
       " 0.8097851952225282,\n",
       " 0.19021480477747152,\n",
       " 0.7505401107860193,\n",
       " 0.24945988921398082,\n",
       " 0.8142804575780196,\n",
       " 0.18571954242198063,\n",
       " 0.7420715168153871,\n",
       " 0.25792848318461303,\n",
       " 0.8378048054277708,\n",
       " 0.1621951945722292,\n",
       " 0.8089445670380953,\n",
       " 0.19105543296190486,\n",
       " 0.8306443181748955,\n",
       " 0.16935568182510466,\n",
       " 0.8337800942229572,\n",
       " 0.16621990577704268,\n",
       " 0.8401965616118942,\n",
       " 0.15980343838810618,\n",
       " 0.7845188243943507,\n",
       " 0.21548117560564944,\n",
       " 0.7881878047226981,\n",
       " 0.21181219527730202,\n",
       " 0.809536590124292,\n",
       " 0.19046340987570834,\n",
       " 0.8181183877649947,\n",
       " 0.181881612235005,\n",
       " 0.8129265908643885,\n",
       " 0.18707340913561157,\n",
       " 0.8210383314807054,\n",
       " 0.17896166851929468,\n",
       " 0.7835576680961127,\n",
       " 0.21644233190388718,\n",
       " 0.7830946324050775,\n",
       " 0.21690536759492265,\n",
       " 0.806205119747313,\n",
       " 0.19379488025268699,\n",
       " 0.8266109298565719,\n",
       " 0.17338907014342794,\n",
       " 0.7784667700773205,\n",
       " 0.22153322992267963,\n",
       " 0.8222693874378939,\n",
       " 0.1777306125621059,\n",
       " 0.7719252757982882,\n",
       " 0.22807472420171193,\n",
       " 0.7994410726295632,\n",
       " 0.20055892737043673,\n",
       " 0.7760279594514317,\n",
       " 0.22397204054856792,\n",
       " 0.7902122987485174,\n",
       " 0.20978770125148272,\n",
       " 0.7942772501578653,\n",
       " 0.20572274984213446,\n",
       " 0.8034085769683992,\n",
       " 0.1965914230316014,\n",
       " 0.7827489047229311,\n",
       " 0.21725109527706915,\n",
       " 0.7770158484523262,\n",
       " 0.22298415154767362,\n",
       " 0.8326280040344822,\n",
       " 0.16737199596551786,\n",
       " 0.8289173025500286,\n",
       " 0.17108269744997132,\n",
       " 0.7871172884179758,\n",
       " 0.21288271158202382,\n",
       " 0.8079157613929394,\n",
       " 0.19208423860706045,\n",
       " 0.7488890728417982,\n",
       " 0.25111092715820194,\n",
       " 0.8067177719348037,\n",
       " 0.19328222806519627,\n",
       " 0.7759246223626315,\n",
       " 0.22407537763736907,\n",
       " 0.8048597924292961,\n",
       " 0.19514020757070408,\n",
       " 0.8409769581240816,\n",
       " 0.15902304187591848,\n",
       " 0.820834159287025,\n",
       " 0.1791658407129752,\n",
       " 0.8001175780397172,\n",
       " 0.1998824219602832,\n",
       " 0.8247021084605214,\n",
       " 0.1752978915394785,\n",
       " 0.8429375946558708,\n",
       " 0.15706240534412874,\n",
       " 0.7973936380388043,\n",
       " 0.20260636196119586,\n",
       " 0.767214018507153,\n",
       " 0.23278598149284765,\n",
       " 0.7749518743302513,\n",
       " 0.2250481256697486,\n",
       " 0.8124142840701364,\n",
       " 0.18758571592986384,\n",
       " 0.8077596457385904,\n",
       " 0.1922403542614094,\n",
       " 0.8070254191323051,\n",
       " 0.1929745808676952,\n",
       " 0.7990282172573104,\n",
       " 0.20097178274268956,\n",
       " 0.8329911933698009,\n",
       " 0.16700880663019924,\n",
       " 0.7756471777853854,\n",
       " 0.22435282221461444,\n",
       " 0.8103028127817712,\n",
       " 0.18969718721822867,\n",
       " 0.790058451950216,\n",
       " 0.20994154804978407,\n",
       " 0.8248181036126422,\n",
       " 0.17518189638735782,\n",
       " 0.8201097673183054,\n",
       " 0.17989023268169485,\n",
       " 0.8317624943451759,\n",
       " 0.16823750565482445,\n",
       " 0.7835500578870103,\n",
       " 0.2164499421129897,\n",
       " 0.8037520395016253,\n",
       " 0.196247960498375,\n",
       " 0.7894134789719104,\n",
       " 0.21058652102808953,\n",
       " 0.7995951854207761,\n",
       " 0.20040481457922418,\n",
       " 0.8229085108273857,\n",
       " 0.17709148917261452,\n",
       " 0.8305612522311518,\n",
       " 0.16943874776884799,\n",
       " 0.7735772552780896,\n",
       " 0.22642274472191054,\n",
       " 0.7747169550123431,\n",
       " 0.22528304498765692,\n",
       " 0.8318480364496348,\n",
       " 0.16815196355036513,\n",
       " 0.8428157502260752,\n",
       " 0.15718424977392512,\n",
       " 0.7799722333425874,\n",
       " 0.22002776665741292,\n",
       " 0.7902174803912954,\n",
       " 0.20978251960870453,\n",
       " 0.7676547184294472,\n",
       " 0.23234528157055298,\n",
       " 0.8186353673977202,\n",
       " 0.18136463260227947,\n",
       " 0.8541107152145787,\n",
       " 0.14588928478542112,\n",
       " 0.8230760834017186,\n",
       " 0.17692391659828172,\n",
       " 0.7217945072760215,\n",
       " 0.2782054927239786,\n",
       " 0.782206445590945,\n",
       " 0.21779355440905498,\n",
       " 0.8120852376445663,\n",
       " 0.187914762355434,\n",
       " 0.8119269097771522,\n",
       " 0.1880730902228479,\n",
       " 0.7949473530922055,\n",
       " 0.2050526469077947,\n",
       " 0.8423283174303999,\n",
       " 0.1576716825696003,\n",
       " 0.7799728436822048,\n",
       " 0.22002715631779513,\n",
       " 0.7585005682585304,\n",
       " 0.24149943174146962,\n",
       " 0.7458105164729372,\n",
       " 0.25418948352706305,\n",
       " 0.7898211648195331,\n",
       " 0.21017883518046723,\n",
       " 0.7957158699451671,\n",
       " 0.2042841300548333,\n",
       " 0.8575964437582273,\n",
       " 0.1424035562417729,\n",
       " 0.8011504068236758,\n",
       " 0.19884959317632445,\n",
       " 0.7807620788911309,\n",
       " 0.21923792110886903,\n",
       " 0.8407645327335592,\n",
       " 0.15923546726644092,\n",
       " 0.7978066333780299,\n",
       " 0.20219336662197054,\n",
       " 0.7967651325393841,\n",
       " 0.2032348674606162,\n",
       " 0.8153950914522234,\n",
       " 0.18460490854777642,\n",
       " 0.8242140843782393,\n",
       " 0.1757859156217607,\n",
       " 0.8007133342261767,\n",
       " 0.19928666577382373,\n",
       " 0.8282078823497591,\n",
       " 0.17179211765024108,\n",
       " 0.8244574447408187,\n",
       " 0.17554255525918117,\n",
       " 0.8372146160373252,\n",
       " 0.1627853839626745,\n",
       " 0.8087543473323929,\n",
       " 0.19124565266760743,\n",
       " 0.806019777057452,\n",
       " 0.1939802229425478,\n",
       " 0.7800699201880735,\n",
       " 0.21993007981192655,\n",
       " 0.7287167889425311,\n",
       " 0.27128321105746894,\n",
       " 0.8058802751175395,\n",
       " 0.19411972488246027,\n",
       " 0.8294535371523211,\n",
       " 0.170546462847679,\n",
       " 0.8232122489973628,\n",
       " 0.17678775100263727,\n",
       " 0.7796493568364284,\n",
       " 0.22035064316357172,\n",
       " 0.8404685339587797,\n",
       " 0.15953146604122007,\n",
       " 0.7847683690400493,\n",
       " 0.2152316309599507,\n",
       " 0.7369023560921719,\n",
       " 0.26309764390782847,\n",
       " 0.8007322315423235,\n",
       " 0.1992677684576768,\n",
       " 0.7864226367955505,\n",
       " 0.21357736320444962,\n",
       " 0.7874157847787565,\n",
       " 0.21258421522124393,\n",
       " 0.8229778185512392,\n",
       " 0.17702218144876108,\n",
       " 0.8106512764402182,\n",
       " 0.18934872355978172,\n",
       " 0.8334479743305205,\n",
       " 0.16655202566947908,\n",
       " 0.8450540739632082,\n",
       " 0.154945926036792,\n",
       " 0.7626174855392547,\n",
       " 0.2373825144607454,\n",
       " 0.8315306839444147,\n",
       " 0.16846931605558566,\n",
       " 0.6736174110587811,\n",
       " 0.3263825889412192,\n",
       " 0.766194207392789,\n",
       " 0.23380579260721096,\n",
       " 0.8227812671266629,\n",
       " 0.17721873287333723,\n",
       " 0.7889089186835967,\n",
       " 0.21109108131640383,\n",
       " 0.8272952603056819,\n",
       " 0.17270473969431824,\n",
       " 0.7907306086451982,\n",
       " 0.2092693913548018,\n",
       " 0.7675829459396359,\n",
       " 0.23241705406036434,\n",
       " 0.8023909859813052,\n",
       " 0.19760901401869474,\n",
       " 0.7107121771501841,\n",
       " 0.28928782284981613,\n",
       " 0.8271349028781458,\n",
       " 0.17286509712185413,\n",
       " 0.8417006533911809,\n",
       " 0.15829934660881934,\n",
       " 0.7922601175659092,\n",
       " 0.2077398824340911,\n",
       " 0.8217420545632508,\n",
       " 0.17825794543674917,\n",
       " 0.8011268454429775,\n",
       " 0.19887315455702254,\n",
       " 0.828548465439836,\n",
       " 0.17145153456016377,\n",
       " 0.773394008100424,\n",
       " 0.226605991899576,\n",
       " 0.7934432570185268,\n",
       " 0.20655674298147328,\n",
       " 0.8231084514962107,\n",
       " 0.17689154850378963,\n",
       " 0.8140860882060089,\n",
       " 0.18591391179399122,\n",
       " 0.780350664559705,\n",
       " 0.21964933544029552,\n",
       " 0.8097469919726512,\n",
       " 0.19025300802734865,\n",
       " 0.8349152576556393,\n",
       " 0.16508474234436057,\n",
       " 0.7557325620941648,\n",
       " 0.24426743790583547,\n",
       " 0.7156717637905412,\n",
       " 0.28432823620945863,\n",
       " 0.7885615597901787,\n",
       " 0.21143844020982133,\n",
       " 0.8153681916897538,\n",
       " 0.18463180831024611,\n",
       " 0.747087131416127,\n",
       " 0.2529128685838729,\n",
       " 0.8316166119701016,\n",
       " 0.16838338802989863,\n",
       " 0.7399939999868327,\n",
       " 0.2600060000131671,\n",
       " 0.8178536411573194,\n",
       " 0.18214635884268074,\n",
       " 0.7737274753468982,\n",
       " 0.22627252465310213,\n",
       " 0.8266321974146825,\n",
       " 0.17336780258531753,\n",
       " 0.7978461178602504,\n",
       " 0.2021538821397496,\n",
       " 0.7922519409550496,\n",
       " 0.20774805904495042,\n",
       " 0.7714234489336773,\n",
       " 0.22857655106632302,\n",
       " 0.8075113411053313,\n",
       " 0.19248865889466857,\n",
       " 0.7798874613339329,\n",
       " 0.22011253866606725,\n",
       " 0.7455636638711438,\n",
       " 0.2544363361288562,\n",
       " 0.7817719851481715,\n",
       " 0.21822801485182847,\n",
       " 0.8268606342146831,\n",
       " 0.17313936578531675,\n",
       " 0.8106821378574907,\n",
       " 0.18931786214250945,\n",
       " 0.782818797575717,\n",
       " 0.21718120242428313,\n",
       " 0.7980739317967772,\n",
       " 0.20192606820322326,\n",
       " 0.8293706036824402,\n",
       " 0.17062939631756016,\n",
       " 0.7442427558239879,\n",
       " 0.2557572441760122,\n",
       " 0.8134200054725187,\n",
       " 0.18657999452748125,\n",
       " 0.8440020633260334,\n",
       " 0.15599793667396666,\n",
       " 0.7815507737143632,\n",
       " 0.21844922628563715,\n",
       " 0.8411413225056675,\n",
       " 0.1588586774943321,\n",
       " 0.8032045845909872,\n",
       " 0.19679541540901302,\n",
       " 0.8500714292992284,\n",
       " 0.1499285707007715,\n",
       " 0.8068831273972268,\n",
       " 0.19311687260277313,\n",
       " 0.828809889940432,\n",
       " 0.1711901100595677,\n",
       " 0.796984748832752,\n",
       " 0.2030152511672484,\n",
       " 0.8160226137232302,\n",
       " 0.1839773862767702,\n",
       " 0.7835174625340159,\n",
       " 0.216482537465984,\n",
       " 0.8000555362467836,\n",
       " 0.19994446375321653,\n",
       " 0.7726373991069723,\n",
       " 0.2273626008930282,\n",
       " 0.8040537364513531,\n",
       " 0.195946263548647,\n",
       " 0.7729725755176521,\n",
       " 0.2270274244823481,\n",
       " 0.8447402684571266,\n",
       " 0.1552597315428732,\n",
       " 0.8063765532317397,\n",
       " 0.1936234467682603,\n",
       " 0.7862532620327157,\n",
       " 0.21374673796728424,\n",
       " 0.7906646573414199,\n",
       " 0.20933534265858034,\n",
       " 0.803720963310797,\n",
       " 0.1962790366892031,\n",
       " 0.8188788421962481,\n",
       " 0.1811211578037521,\n",
       " 0.8165758689544113,\n",
       " 0.1834241310455888,\n",
       " 0.8211540872383316,\n",
       " 0.1788459127616687,\n",
       " 0.7600806322079348,\n",
       " 0.23991936779206513,\n",
       " 0.8159119423574497,\n",
       " 0.1840880576425504,\n",
       " 0.8137864171688147,\n",
       " 0.18621358283118566,\n",
       " 0.7643490272964805,\n",
       " 0.2356509727035198,\n",
       " 0.8415470689925965,\n",
       " 0.15845293100740349,\n",
       " 0.8068272874485523,\n",
       " 0.19317271255144797,\n",
       " 0.8399235222476079,\n",
       " 0.16007647775239234,\n",
       " 0.7846985083312635,\n",
       " 0.2153014916687368,\n",
       " 0.8198431466021647,\n",
       " 0.18015685339783535,\n",
       " 0.7961303567071336,\n",
       " 0.2038696432928662,\n",
       " 0.8137892150646614,\n",
       " 0.18621078493533855,\n",
       " 0.8025069263690828,\n",
       " 0.1974930736309173,\n",
       " 0.827367509713167,\n",
       " 0.1726324902868335,\n",
       " 0.8126520066691322,\n",
       " 0.18734799333086818,\n",
       " 0.6951743402100052,\n",
       " 0.30482565978999493,\n",
       " 0.7822649624720008,\n",
       " 0.21773503752799936,\n",
       " 0.7863182432793895,\n",
       " 0.21368175672061068,\n",
       " 0.8253875472349192,\n",
       " 0.17461245276508106,\n",
       " 0.8217279191218014,\n",
       " 0.17827208087819899,\n",
       " 0.7756388758055417,\n",
       " 0.22436112419445822,\n",
       " 0.7912507073722692,\n",
       " 0.20874929262773112,\n",
       " 0.7741990624929902,\n",
       " 0.22580093750700977,\n",
       " 0.8192179716393666,\n",
       " 0.18078202836063378,\n",
       " 0.7936819684213815,\n",
       " 0.2063180315786184,\n",
       " 0.7168821203985791,\n",
       " 0.2831178796014211,\n",
       " 0.7749316240613858,\n",
       " 0.2250683759386142,\n",
       " 0.7864751487185505,\n",
       " 0.21352485128144955,\n",
       " 0.7414274839652454,\n",
       " 0.25857251603475456,\n",
       " 0.8151955064475217,\n",
       " 0.18480449355247813,\n",
       " 0.8309692582741142,\n",
       " 0.16903074172588578,\n",
       " 0.8268041518377691,\n",
       " 0.17319584816223088,\n",
       " 0.8313432338948762,\n",
       " 0.16865676610512356,\n",
       " 0.8368850060945238,\n",
       " 0.16311499390547618,\n",
       " 0.7940270485853818,\n",
       " 0.20597295141461827,\n",
       " 0.7800856502221643,\n",
       " 0.21991434977783578,\n",
       " 0.7373821200577982,\n",
       " 0.26261787994220154,\n",
       " 0.8399728857454126,\n",
       " 0.16002711425458774,\n",
       " 0.8238058776507826,\n",
       " 0.1761941223492177,\n",
       " 0.7968602719562182,\n",
       " 0.20313972804378197,\n",
       " 0.8056265101555681,\n",
       " 0.19437348984443187,\n",
       " 0.8063934734292624,\n",
       " 0.19360652657073757,\n",
       " 0.7875602235282809,\n",
       " 0.21243977647171872,\n",
       " 0.778549979637666,\n",
       " 0.2214500203623341,\n",
       " 0.731915429686905,\n",
       " 0.2680845703130951,\n",
       " 0.7834322148244898,\n",
       " 0.21656778517551045,\n",
       " 0.8062226989344619,\n",
       " 0.19377730106553806,\n",
       " 0.7791196614366172,\n",
       " 0.22088033856338307,\n",
       " 0.8274720275328299,\n",
       " 0.17252797246716972,\n",
       " 0.8297181428476498,\n",
       " 0.17028185715235072,\n",
       " 0.7487159872865746,\n",
       " 0.2512840127134255,\n",
       " 0.7964711998236426,\n",
       " 0.20352880017635744,\n",
       " 0.7967284766375411,\n",
       " 0.203271523362459,\n",
       " 0.7757146974183567,\n",
       " 0.2242853025816434,\n",
       " 0.7878578348043359,\n",
       " 0.2121421651956642,\n",
       " 0.8021989769594768,\n",
       " 0.19780102304052372,\n",
       " 0.7611643815249812,\n",
       " 0.23883561847501922,\n",
       " 0.7844712784028868,\n",
       " 0.21552872159711345,\n",
       " 0.7914262099897749,\n",
       " 0.2085737900102257,\n",
       " 0.804680224485866,\n",
       " 0.19531977551413413,\n",
       " 0.8270239126948318,\n",
       " 0.17297608730516842,\n",
       " 0.812318289623534,\n",
       " 0.18768171037646572,\n",
       " 0.7984763660516002,\n",
       " 0.2015236339484,\n",
       " 0.7769060090796824,\n",
       " 0.22309399092031765,\n",
       " 0.8174606873081696,\n",
       " 0.1825393126918306,\n",
       " 0.7916102616299644,\n",
       " 0.20838973837003558,\n",
       " 0.7802343366442867,\n",
       " 0.2197656633557137,\n",
       " 0.8568915633309593,\n",
       " 0.14310843666904113,\n",
       " 0.8154412330472744,\n",
       " 0.18455876695272547,\n",
       " 0.8318964991748808,\n",
       " 0.16810350082511957,\n",
       " 0.7629790463986004,\n",
       " 0.2370209536013996,\n",
       " 0.8373611438086164,\n",
       " 0.1626388561913837,\n",
       " 0.7105874353524658,\n",
       " 0.28941256464753407,\n",
       " 0.8022948663474017,\n",
       " 0.19770513365259856,\n",
       " 0.8087908909844945,\n",
       " 0.19120910901550595,\n",
       " 0.7972247876636199,\n",
       " 0.20277521233638002,\n",
       " 0.8204432529614598,\n",
       " 0.17955674703854071,\n",
       " 0.701997940294428,\n",
       " 0.29800205970557186,\n",
       " 0.7906222911621679,\n",
       " 0.20937770883783208,\n",
       " 0.8426344773268087,\n",
       " 0.15736552267319165,\n",
       " 0.8200992827170398,\n",
       " 0.17990071728296023,\n",
       " 0.7477864027405902,\n",
       " 0.25221359725941,\n",
       " 0.7234507477215104,\n",
       " 0.27654925227848953,\n",
       " 0.8095685226137016,\n",
       " 0.1904314773862982,\n",
       " 0.8258515276927256,\n",
       " 0.17414847230727432,\n",
       " 0.7934920857125707,\n",
       " 0.2065079142874297,\n",
       " 0.8432732018434492,\n",
       " 0.15672679815655088,\n",
       " 0.7873603970820582,\n",
       " 0.21263960291794212,\n",
       " 0.8468990557221275,\n",
       " 0.15310094427787196,\n",
       " 0.8106659118635793,\n",
       " 0.189334088136421,\n",
       " 0.7888984399551924,\n",
       " 0.21110156004480773,\n",
       " 0.674256516035926,\n",
       " 0.3257434839640742,\n",
       " 0.8073093734199125,\n",
       " 0.19269062658008784,\n",
       " 0.8003999129344704,\n",
       " 0.19960008706552976,\n",
       " 0.8088834680242983,\n",
       " 0.19111653197570136,\n",
       " 0.8372731161662084,\n",
       " 0.16272688383379155,\n",
       " 0.8257293341870638,\n",
       " 0.17427066581293585,\n",
       " 0.7975315363075434,\n",
       " 0.20246846369245627,\n",
       " 0.8143938559773346,\n",
       " 0.18560614402266562,\n",
       " 0.79254984873215,\n",
       " 0.20745015126785005,\n",
       " 0.8166578242490808,\n",
       " 0.18334217575091863,\n",
       " 0.7690188316346819,\n",
       " 0.2309811683653181,\n",
       " 0.8223896745611299,\n",
       " 0.17761032543887004,\n",
       " 0.8376591076741638,\n",
       " 0.16234089232583618,\n",
       " 0.7365630758109067,\n",
       " 0.26343692418909337,\n",
       " 0.812179215212952,\n",
       " 0.18782078478704833,\n",
       " 0.7272308666697482,\n",
       " 0.27276913333025193,\n",
       " 0.7479554454487287,\n",
       " 0.2520445545512716,\n",
       " 0.7866038858785909,\n",
       " 0.21339611412140894,\n",
       " 0.8171956693298739,\n",
       " 0.182804330670126,\n",
       " 0.8488109162835756,\n",
       " 0.15118908371642495,\n",
       " 0.78468160869582,\n",
       " 0.21531839130417985,\n",
       " 0.790177872733028,\n",
       " 0.20982212726697186,\n",
       " 0.838207977431517,\n",
       " 0.16179202256848296,\n",
       " 0.8120879056886402,\n",
       " 0.18791209431135972,\n",
       " 0.8156664992193862,\n",
       " 0.18433350078061386,\n",
       " 0.7942357202023613,\n",
       " 0.2057642797976385,\n",
       " 0.7817863748695184,\n",
       " 0.21821362513048143,\n",
       " 0.7880888924675378,\n",
       " 0.21191110753246226,\n",
       " 0.8435859542479605,\n",
       " 0.15641404575203977,\n",
       " 0.8202164295768025,\n",
       " 0.1797835704231974,\n",
       " 0.8023595670950064,\n",
       " 0.19764043290499397,\n",
       " 0.8227792741102233,\n",
       " 0.17722072588977664,\n",
       " 0.8263690664485795,\n",
       " 0.1736309335514205,\n",
       " 0.8094612758930632,\n",
       " 0.19053872410693679,\n",
       " 0.81795448859827,\n",
       " 0.18204551140173014,\n",
       " 0.8357070329890968,\n",
       " 0.16429296701090382,\n",
       " 0.7543112181021621,\n",
       " 0.24568878189783805,\n",
       " 0.845968288263574,\n",
       " 0.154031711736426,\n",
       " 0.7935250721102299,\n",
       " 0.20647492788976993,\n",
       " 0.7889673640190764,\n",
       " 0.2110326359809239,\n",
       " 0.8336168862389678,\n",
       " 0.16638311376103254,\n",
       " 0.7660254701801109,\n",
       " 0.23397452981988917,\n",
       " 0.814809493036813,\n",
       " 0.18519050696318737,\n",
       " 0.8029318093654129,\n",
       " 0.19706819063458736,\n",
       " 0.7645375920589939,\n",
       " 0.235462407941006,\n",
       " 0.7923523460157695,\n",
       " 0.20764765398423057,\n",
       " 0.7356280699974468,\n",
       " 0.2643719300025533,\n",
       " 0.814126537101596,\n",
       " 0.18587346289840398,\n",
       " 0.7719985914692593,\n",
       " 0.22800140853074036,\n",
       " 0.790296877884034,\n",
       " 0.20970312211596578,\n",
       " 0.6601486961262931,\n",
       " 0.33985130387370693,\n",
       " 0.7568348759772116,\n",
       " 0.24316512402278864,\n",
       " 0.8229928869042545,\n",
       " 0.17700711309574546,\n",
       " 0.8068041249961219,\n",
       " 0.19319587500387808,\n",
       " 0.8469395849618584,\n",
       " 0.15306041503814138,\n",
       " 0.823421702846864,\n",
       " 0.17657829715313583,\n",
       " 0.8021557053352726,\n",
       " 0.1978442946647273,\n",
       " 0.8324668374711517,\n",
       " 0.16753316252884837,\n",
       " 0.8184552402198458,\n",
       " 0.1815447597801543,\n",
       " 0.8238832136066726,\n",
       " 0.17611678639332717,\n",
       " 0.7877314988655637,\n",
       " 0.21226850113443624,\n",
       " 0.7998614775863405,\n",
       " 0.20013852241365934,\n",
       " 0.8298416360560676,\n",
       " 0.1701583639439326,\n",
       " 0.827217045466129,\n",
       " 0.17278295453387094,\n",
       " 0.7904110953473333,\n",
       " 0.20958890465266733,\n",
       " 0.7940678529367402,\n",
       " 0.20593214706325974,\n",
       " 0.8202807908112655,\n",
       " 0.17971920918873469,\n",
       " 0.8424434687548985,\n",
       " 0.1575565312451017,\n",
       " 0.8213391056627793,\n",
       " 0.1786608943372211,\n",
       " 0.81390626811696,\n",
       " 0.18609373188304035,\n",
       " 0.7955174647137184,\n",
       " 0.2044825352862818,\n",
       " 0.808987619767588,\n",
       " 0.191012380232412,\n",
       " 0.8202465191000959,\n",
       " 0.17975348089990423,\n",
       " 0.829244627634376,\n",
       " 0.17075537236562416,\n",
       " 0.7416722594702394,\n",
       " 0.2583277405297605,\n",
       " 0.7418740415166191,\n",
       " 0.258125958483381,\n",
       " 0.7881522252647621,\n",
       " 0.2118477747352379,\n",
       " 0.7895522655764267,\n",
       " 0.2104477344235734,\n",
       " 0.8125449226210202,\n",
       " 0.18745507737897957,\n",
       " 0.8200797936948218,\n",
       " 0.17992020630517813,\n",
       " 0.8262105117763486,\n",
       " 0.17378948822365137,\n",
       " 0.809529305394393,\n",
       " 0.1904706946056072,\n",
       " 0.6643549484444817,\n",
       " 0.33564505155551805,\n",
       " 0.810621305633773,\n",
       " 0.1893786943662275,\n",
       " 0.8013277100372221,\n",
       " 0.19867228996277853,\n",
       " 0.7765397397732926,\n",
       " 0.2234602602267074,\n",
       " 0.8492499505671185,\n",
       " 0.15075004943288142,\n",
       " 0.7212293681686193,\n",
       " 0.2787706318313811,\n",
       " 0.8002414961825149,\n",
       " 0.1997585038174856,\n",
       " 0.8058659950267372,\n",
       " 0.19413400497326297,\n",
       " 0.8103446997483655,\n",
       " 0.18965530025163446,\n",
       " 0.8037286784513347,\n",
       " 0.19627132154866536,\n",
       " 0.8020937866767274,\n",
       " 0.19790621332327268,\n",
       " 0.7531896035133231,\n",
       " 0.24681039648667702,\n",
       " 0.777014239909329,\n",
       " 0.2229857600906715,\n",
       " 0.8022916965609121,\n",
       " 0.19770830343908796,\n",
       " 0.8004671017931373,\n",
       " 0.1995328982068628,\n",
       " 0.7514632132225176,\n",
       " 0.24853678677748245,\n",
       " 0.8108176419664739,\n",
       " 0.1891823580335262,\n",
       " 0.7785319711860837,\n",
       " 0.22146802881391633,\n",
       " 0.742687525134578,\n",
       " 0.25731247486542186,\n",
       " 0.7925217137485427,\n",
       " 0.2074782862514574,\n",
       " 0.7618100087380886,\n",
       " 0.23818999126191162,\n",
       " 0.819953763755393,\n",
       " 0.18004623624460694,\n",
       " 0.8072231464344576,\n",
       " 0.19277685356554233,\n",
       " 0.7901911889618651,\n",
       " 0.20980881103813517,\n",
       " 0.825207943742612,\n",
       " 0.17479205625738803,\n",
       " 0.7897730237271063,\n",
       " 0.21022697627289386,\n",
       " 0.7942581863723999,\n",
       " 0.20574181362760008,\n",
       " 0.7907838604310463,\n",
       " 0.20921613956895363,\n",
       " 0.8210813603639316,\n",
       " 0.17891863963606855,\n",
       " 0.7960363791797035,\n",
       " 0.20396362082029657,\n",
       " 0.7797418544963378,\n",
       " 0.22025814550366218,\n",
       " 0.825151347918245,\n",
       " 0.17484865208175493,\n",
       " 0.8100362960143407,\n",
       " 0.18996370398565918,\n",
       " 0.7963026704433237,\n",
       " 0.20369732955667627,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Description for train data\n",
    "desc_files = len(os.listdir('../descriptions_train'))\n",
    "all_desc_train = []\n",
    "\n",
    "for i in range(desc_files):\n",
    "    empty_str = ''\n",
    "    for line in open(f'../descriptions_train/{i}.txt'):\n",
    "        empty_str += line.replace('\\n',' ')\n",
    "    all_desc_train.append(empty_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tags for train data\n",
    "tag_files = len(os.listdir('../tags_train'))\n",
    "all_tags_train = []\n",
    "\n",
    "for i in range(tag_files):\n",
    "    nouns = ''\n",
    "    for line in open(f'../tags_train/{i}.txt'):\n",
    "        nouns += line.replace(':',' ')\n",
    "    all_tags_train.append(nouns.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Description for test data\n",
    "desc_files = len(os.listdir('../descriptions_test'))\n",
    "all_desc_test = []\n",
    "\n",
    "for i in range(desc_files):\n",
    "    empty_str = ''\n",
    "    for line in open(f'../descriptions_test/{i}.txt'):\n",
    "        empty_str += line.replace('\\n',' ')\n",
    "    all_desc_test.append(empty_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tags for test data\n",
    "tag_files = len(os.listdir('../tags_test'))\n",
    "all_tags_test = []\n",
    "\n",
    "for i in range(tag_files):\n",
    "    nouns = ''\n",
    "    for line in open(f'../tags_test/{i}.txt'):\n",
    "        nouns += line.replace(':',' ')\n",
    "    all_tags_test.append(nouns.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = []\n",
    "all_docs.extend(all_desc_train)\n",
    "all_docs.extend(all_desc_test)\n",
    "all_docs.extend(all_tags_train)\n",
    "all_docs.extend(all_tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1000 = pd.read_csv('../features_train/features_resnet1000_train.csv', header=None)\n",
    "train_2048 = pd.read_csv('../features_train/features_resnet1000intermediate_train.csv', header=None)\n",
    "test_1000 = pd.read_csv('../features_test/features_resnet1000_test.csv', header=None)\n",
    "test_2048 = pd.read_csv('../features_test/features_resnet1000intermediate_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num(string):\n",
    "    string = string.replace('.', ' ').replace('/', ' ')\n",
    "    num = [int(s) for s in string.split() if s.isdigit()]\n",
    "    return num[0]\n",
    "\n",
    "def parse_to_numpy(pd):\n",
    "    images_idx = []\n",
    "    for string in pd[0]:\n",
    "        images_idx.append(get_num(string))\n",
    "\n",
    "    pd.insert(1, \"Image_Index\", images_idx, True)\n",
    "    pd = pd.sort_values(by=['Image_Index'])\n",
    "    pd = pd.reset_index(drop=True)\n",
    "    del pd['Image_Index']\n",
    "    del pd[0]\n",
    "    np = pd.to_numpy()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1000 = parse_to_numpy(train_1000)\n",
    "train_2048 = parse_to_numpy(train_2048)\n",
    "test_1000 = parse_to_numpy(test_1000)\n",
    "test_2048 = parse_to_numpy(test_2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Google embedding\n",
    "#tf.enable_eager_execution()\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "### Overwrite old train_desc and test_desc\n",
    "train_desc = embed(all_desc_train).numpy()\n",
    "test_desc = embed(all_desc_test).numpy()\n",
    "train_tags = embed(all_tags_train).numpy()\n",
    "test_tags = embed(all_tags_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pic = np.hstack((train_1000, train_2048))#, train_tags))\n",
    "test_pic = np.hstack((test_1000, test_2048))#, test_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "# path = get_tmpfile(\"word2vec.model\")\n",
    "# model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n",
    "# model.save(\"word2vec.model\")\n",
    "# model = Word2Vec.load(\"word2vec.model\")\n",
    "# model.train([all_desc_train], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 512), (10000, 3048), (2000, 512), (2000, 3048))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_desc.shape, train_pic.shape, test_desc.shape, test_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 512), (10000, 3048), (2000, 512), (2000, 3048))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_desc.shape, train_pic.shape, test_desc.shape, test_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vecs,pics):\n",
    "    dists = pairwise_distances(vecs,pics,metric='cosine')\n",
    "    return dists.T.argsort(1)\n",
    "def map_20(ranks):\n",
    "    return np.mean([(20-rank)/20 if rank<20 else 0 for rank in ranks])\n",
    "def evaluate(vectors,label_vectors):\n",
    "    preds = get_prediction(vectors,label_vectors)\n",
    "    ranks = [np.argwhere(vec==i)[0][0] for i,vec in enumerate(preds)]\n",
    "    return np.mean(ranks),map_20(ranks)\n",
    "def get_top_20(descr_id):\n",
    "    return preds[descr_id][:20]\n",
    "def save_submission():\n",
    "    data = []\n",
    "    for i in range(2000):\n",
    "        data.append(['%d.txt' % (i,),' '.join('%d.jpg' % (pic_id,) for pic_id in get_top_20(i))])\n",
    "    pd.DataFrame(data,columns=['Descritpion_ID','Top_20_Image_IDs']).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.526, 0.7270999999999999)\n",
      "(7.78, 0.7249249999999999)\n",
      "(7.6995, 0.72385)\n",
      "(7.1675, 0.73025)\n",
      "(7.383, 0.719275)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "rcv = RidgeCV(alphas=np.linspace(1.3,8,20))\n",
    "for train_index, test_index in kf.split(train_pic):\n",
    "    rcv.fit(train_pic[train_index], train_desc[train_index])\n",
    "    pred = rcv.predict(train_pic[test_index])\n",
    "    output = evaluate(pred, train_desc[test_index])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(train_desc, train_pic)\n",
    "prediction = regr.predict(test_desc)\n",
    "preds = get_prediction(prediction, test_pic)\n",
    "save_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:09:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.fit(train_pic, train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

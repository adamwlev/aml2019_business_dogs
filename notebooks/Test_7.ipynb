{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Description for train data\n",
    "desc_files = len(os.listdir('../descriptions_train'))\n",
    "all_desc_train = []\n",
    "\n",
    "for i in range(desc_files):\n",
    "    empty_str = ''\n",
    "    for line in open(f'../descriptions_train/{i}.txt'):\n",
    "        empty_str += line.replace('\\n',' ')\n",
    "    all_desc_train.append(empty_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tags for train data\n",
    "tag_files = len(os.listdir('../tags_train'))\n",
    "all_tags_train = []\n",
    "\n",
    "for i in range(tag_files):\n",
    "    nouns = ''\n",
    "    for line in open(f'../tags_train/{i}.txt'):\n",
    "        nouns += line.replace(':',' ')\n",
    "    all_tags_train.append(nouns.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Description for test data\n",
    "desc_files = len(os.listdir('../descriptions_test'))\n",
    "all_desc_test = []\n",
    "\n",
    "for i in range(desc_files):\n",
    "    empty_str = ''\n",
    "    for line in open(f'../descriptions_test/{i}.txt'):\n",
    "        empty_str += line.replace('\\n',' ')\n",
    "    all_desc_test.append(empty_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tags for test data\n",
    "tag_files = len(os.listdir('../tags_test'))\n",
    "all_tags_test = []\n",
    "\n",
    "for i in range(tag_files):\n",
    "    nouns = ''\n",
    "    for line in open(f'../tags_test/{i}.txt'):\n",
    "        nouns += line.replace(':',' ')\n",
    "    all_tags_test.append(nouns.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = []\n",
    "all_docs.extend(all_desc_train)\n",
    "all_docs.extend(all_desc_test)\n",
    "all_docs.extend(all_tags_train)\n",
    "all_docs.extend(all_tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=‘english’, min_df=2)\n",
    "vectorizer.fit(all_docs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_desc = vectorizer.transform(all_desc_train)\n",
    "test_desc = vectorizer.transform(all_desc_test)\n",
    "train_tags = vectorizer.transform(all_tags_train)\n",
    "test_tags = vectorizer.transform(all_tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_desc = np.array(train_desc.todense())\n",
    "test_desc = np.array(test_desc.todense())\n",
    "train_tags = np.array(train_tags.todense())\n",
    "test_tags = np.array(test_tags.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1000 = pd.read_csv('../features_train/features_resnet1000_train.csv', header=None)\n",
    "train_2048 = pd.read_csv('../features_train/features_resnet1000intermediate_train.csv', header=None)\n",
    "test_1000 = pd.read_csv('../features_test/features_resnet1000_test.csv', header=None)\n",
    "test_2048 = pd.read_csv('../features_test/features_resnet1000intermediate_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num(string):\n",
    "    string = string.replace('.', ' ').replace('/', ' ')\n",
    "    num = [int(s) for s in string.split() if s.isdigit()]\n",
    "    return num[0]\n",
    "\n",
    "def parse_to_numpy(pd):\n",
    "    images_idx = []\n",
    "    for string in pd[0]:\n",
    "        images_idx.append(get_num(string))\n",
    "\n",
    "    pd.insert(1, \"Image_Index\", images_idx, True)\n",
    "    pd = pd.sort_values(by=['Image_Index'])\n",
    "    pd = pd.reset_index(drop=True)\n",
    "    del pd['Image_Index']\n",
    "    del pd[0]\n",
    "    np = pd.to_numpy()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1000 = parse_to_numpy(train_1000)\n",
    "train_2048 = parse_to_numpy(train_2048)\n",
    "test_1000 = parse_to_numpy(test_1000)\n",
    "test_2048 = parse_to_numpy(test_2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5de6f2e4dabf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_tags' is not defined"
     ]
    }
   ],
   "source": [
    "train = np.hstack((train_1000, train_2048, train_tags))\n",
    "test = np.hstack((test_1000, test_2048, test_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_desc.shape, train.shape, test_desc.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set PCA Dimensions\n",
    "pca = PCA(n_components = 100)\n",
    "pca.fit(train)\n",
    "train = pca.transform(train)\n",
    "test = pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_desc.shape, train.shape, test_desc.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vecs,pics):\n",
    "    dists = pairwise_distances(vecs,pics,metric='cosine')\n",
    "    return dists.argsort(1)\n",
    "def map_20(ranks):\n",
    "    return np.mean([(20-rank)/20 if rank<20 else 0 for rank in ranks])\n",
    "def evaluate(vectors,label_vectors):\n",
    "    preds = get_prediction(vectors,label_vectors)\n",
    "    ranks = [np.argwhere(vec==i)[0][0] for i,vec in enumerate(preds)]\n",
    "    return np.mean(ranks),map_20(ranks)\n",
    "def get_top_20(descr_id):\n",
    "    return preds[descr_id][:20]\n",
    "def save_submission():\n",
    "    data = []\n",
    "    for i in range(2000):\n",
    "        data.append(['%d.txt' % (i,),' '.join('%d.jpg' % (pic_id,) for pic_id in get_top_20(i))])\n",
    "    pd.DataFrame(data,columns=['Descritpion_ID','Top_20_Image_IDs']).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000 2001 2002 ... 9997 9998 9999] [   0    1    2 ... 1997 1998 1999]\n",
      "[   0    1    2 ... 9997 9998 9999] [2000 2001 2002 ... 3997 3998 3999]\n",
      "[   0    1    2 ... 9997 9998 9999] [4000 4001 4002 ... 5997 5998 5999]\n",
      "[   0    1    2 ... 9997 9998 9999] [6000 6001 6002 ... 7997 7998 7999]\n",
      "[   0    1    2 ... 7997 7998 7999] [8000 8001 8002 ... 9997 9998 9999]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "regr = RandomForestRegressor(verbose=3, n_jobs=-1, max_depth=15)\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    regr.fit(train_desc[train_index], train[train_index])\n",
    "    pred = regr.predict(train_desc[test_index])\n",
    "    output = evaluate(pred, train[test_index])\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "def lower(word):\n",
    "    return word.lower()\n",
    "\n",
    "lemm = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize(word):\n",
    "    return lemm.lemmatize(word)\n",
    "\n",
    "punct = set(string.punctuation)\n",
    "def no_punctuation(word):\n",
    "    return ''.join(c for c in word if c not in punct)\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "def no_stop_words(word):\n",
    "    return word if word not in stop_words else ''\n",
    "\n",
    "strategy_map = {'lo':lower,'lem':lemmatize,\n",
    "                'punct':no_punctuation,'stop':no_stop_words}\n",
    "\n",
    "def preprocess(docs,strategies):\n",
    "    for strategy in strategies:\n",
    "        new_docs = []\n",
    "        for doc in docs:\n",
    "            new_doc = []\n",
    "            for word in doc:\n",
    "                transformed = strategy_map[strategy](word)\n",
    "                if transformed:\n",
    "                    new_doc.append(transformed)\n",
    "            new_docs.append(new_doc)\n",
    "        docs = new_docs\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_train = []\n",
    "for i in range(10000):\n",
    "    with open('../descriptions_train/%d.txt' % (i,)) as f:\n",
    "        documents_train.append(f.read().split())\n",
    "documents_train = preprocess(documents_train,['lo','punct'])\n",
    "\n",
    "documents_test = []\n",
    "for i in range(2000):\n",
    "    with open('../descriptions_test/%d.txt' % (i,)) as f:\n",
    "        documents_test.append(f.read().split())\n",
    "documents_test = preprocess(documents_test,['lo','punct'])\n",
    "\n",
    "tag_docs_train = []\n",
    "for i in range(10000):\n",
    "    with open('../tags_train/%d.txt' % (i,),'r') as f:\n",
    "        tag_docs_train.append([word for line in f.read().split('\\n') for word in line.split(':') if word])\n",
    "tag_docs_train = preprocess(tag_docs_train,['lo','punct'])\n",
    "\n",
    "tag_docs_test = []\n",
    "for i in range(2000):\n",
    "    with open('../tags_test/%d.txt' % (i,),'r') as f:\n",
    "        tag_docs_test.append([word for line in f.read().split('\\n') for word in line.split(':') if word])\n",
    "tag_docs_test = preprocess(tag_docs_test,['lo','punct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stop_words,min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit([' '.join(doc) for copus in [documents_train, tag_docs_train] for doc in copus]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = np.array(tfidf.transform([' '.join(doc) for doc in documents_train]).todense())\n",
    "text_test = np.array(tfidf.transform([' '.join(doc) for doc in documents_test]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train = np.array(tfidf.transform([' '.join(doc) for doc in tag_docs_train]).todense())\n",
    "tags_test = np.array(tfidf.transform([' '.join(doc) for doc in tag_docs_test]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5510), (2000, 5510))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape,text_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5510), (2000, 5510))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_train.shape,tags_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5510.000000\n",
       "mean        0.000374\n",
       "std         0.004740\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         0.233749\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.abs(tags_test.mean(0))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_train = pd.read_csv('../features_train/features_resnet1000intermediate_train.csv',header=None)\n",
    "feats_train_b = pd.read_csv('../features_train/features_resnet1000_train.csv',header=None)\n",
    "feats_test = pd.read_csv('../features_test/features_resnet1000intermediate_test.csv',header=None)\n",
    "feats_test_b = pd.read_csv('../features_test/features_resnet1000_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images_train/5373.jpg</td>\n",
       "      <td>-0.899450</td>\n",
       "      <td>-0.930470</td>\n",
       "      <td>-2.503365</td>\n",
       "      <td>-3.172499</td>\n",
       "      <td>-2.819133</td>\n",
       "      <td>0.992159</td>\n",
       "      <td>-3.698863</td>\n",
       "      <td>0.619991</td>\n",
       "      <td>0.956148</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.021916</td>\n",
       "      <td>2.214253</td>\n",
       "      <td>-1.382491</td>\n",
       "      <td>1.672911</td>\n",
       "      <td>1.014233</td>\n",
       "      <td>2.599949</td>\n",
       "      <td>2.773284</td>\n",
       "      <td>-2.066632</td>\n",
       "      <td>0.385754</td>\n",
       "      <td>-3.241320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images_train/984.jpg</td>\n",
       "      <td>-1.346954</td>\n",
       "      <td>-3.119461</td>\n",
       "      <td>-0.765971</td>\n",
       "      <td>-1.382550</td>\n",
       "      <td>-1.104675</td>\n",
       "      <td>-3.656271</td>\n",
       "      <td>-4.815436</td>\n",
       "      <td>-0.556942</td>\n",
       "      <td>-1.402286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>-3.968805</td>\n",
       "      <td>-2.694711</td>\n",
       "      <td>-4.196480</td>\n",
       "      <td>-2.880234</td>\n",
       "      <td>-1.210742</td>\n",
       "      <td>-1.605143</td>\n",
       "      <td>-4.859987</td>\n",
       "      <td>-0.837670</td>\n",
       "      <td>-0.967604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images_train/7127.jpg</td>\n",
       "      <td>-3.445498</td>\n",
       "      <td>-1.524573</td>\n",
       "      <td>-1.001654</td>\n",
       "      <td>-3.668335</td>\n",
       "      <td>-1.805517</td>\n",
       "      <td>-1.633496</td>\n",
       "      <td>-7.127826</td>\n",
       "      <td>-1.147802</td>\n",
       "      <td>-1.055816</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.991777</td>\n",
       "      <td>-2.628053</td>\n",
       "      <td>-2.971074</td>\n",
       "      <td>-2.537039</td>\n",
       "      <td>-1.707429</td>\n",
       "      <td>1.013672</td>\n",
       "      <td>0.608460</td>\n",
       "      <td>-3.714998</td>\n",
       "      <td>-0.484735</td>\n",
       "      <td>0.138767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5     \\\n",
       "0  images_train/5373.jpg -0.899450 -0.930470 -2.503365 -3.172499 -2.819133   \n",
       "1   images_train/984.jpg -1.346954 -3.119461 -0.765971 -1.382550 -1.104675   \n",
       "2  images_train/7127.jpg -3.445498 -1.524573 -1.001654 -3.668335 -1.805517   \n",
       "\n",
       "       6         7         8         9     ...      991       992       993   \\\n",
       "0  0.992159 -3.698863  0.619991  0.956148  ... -3.021916  2.214253 -1.382491   \n",
       "1 -3.656271 -4.815436 -0.556942 -1.402286  ...  0.011003 -3.968805 -2.694711   \n",
       "2 -1.633496 -7.127826 -1.147802 -1.055816  ... -2.991777 -2.628053 -2.971074   \n",
       "\n",
       "       994       995       996       997       998       999       1000  \n",
       "0  1.672911  1.014233  2.599949  2.773284 -2.066632  0.385754 -3.241320  \n",
       "1 -4.196480 -2.880234 -1.210742 -1.605143 -4.859987 -0.837670 -0.967604  \n",
       "2 -2.537039 -1.707429  1.013672  0.608460 -3.714998 -0.484735  0.138767  \n",
       "\n",
       "[3 rows x 1001 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_train_b.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2049), (2000, 2049))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_train.shape,feats_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train = np.zeros((10000,3048))\n",
    "for _,row in feats_train.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_train[i,:2048] = row.values[1:]\n",
    "for _,row in feats_train_b.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_train[i,2048:] = row.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3048.000000\n",
       "mean        0.286300\n",
       "std         0.726504\n",
       "min        -3.890733\n",
       "25%         0.259784\n",
       "50%         0.384236\n",
       "75%         0.526699\n",
       "max         4.441978\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pics_train.mean(0)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_test = np.zeros((2000,3048))\n",
    "for _,row in feats_test.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_test[i,:2048] = row.values[1:]\n",
    "for _,row in feats_test_b.iterrows():\n",
    "    try:\n",
    "        i = int(row[0].split('/')[1].split('.jpg')[0])\n",
    "    except:\n",
    "        i = int(row[0].split('/')[1].split('..jpg')[0])\n",
    "    pics_test[i,2048:] = row.values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3048.000000\n",
       "mean        0.286300\n",
       "std         0.726504\n",
       "min        -3.890733\n",
       "25%         0.259784\n",
       "50%         0.384236\n",
       "75%         0.526699\n",
       "max         4.441978\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pics_train.mean(0)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train = np.hstack([pics_train,tags_train])\n",
    "pics_test = np.hstack([pics_test,tags_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('text_train_full',text_train)\n",
    "# np.save('pics_train_full',pics_train)\n",
    "# np.save('text_test_full',text_test)\n",
    "# np.save('pics_test_full',pics_test)\n",
    "text_train = np.load('text_train_full.npy')\n",
    "pics_train = np.load('pics_train_full.npy')\n",
    "text_test = np.load('text_test_full.npy')\n",
    "pics_test = np.load('pics_test_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(pics_train)\n",
    "pics_train = pca.transform(pics_train)\n",
    "pics_test = pca.transform(pics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5510), (10000, 100))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape,pics_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        if not torch.is_tensor(X):\n",
    "            self.X = torch.tensor(X, requires_grad=True)\n",
    "        if not torch.is_tensor(y):\n",
    "            self.y = torch.tensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,y,X_val,y_val,early_stop_window,H_1):\n",
    "    losses, train_ave, train_map, val_ave, val_map, n_epochs = {}, {}, {}, {}, {}, 0\n",
    "    \n",
    "    ds = PrepareData(X=X, y=y)\n",
    "    dl = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    D_in, D_out = X.shape[1], y.shape[1]\n",
    "    \n",
    "    model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H_1),\n",
    "#           torch.nn.Dropout(0.2),\n",
    "#           torch.nn.BatchNorm1d(H_1),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H_1, D_out),\n",
    "        ).to(device)\n",
    "    \n",
    "    def loss_fn(y_pred, y):\n",
    "        cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        return 1 - cos(y_pred, y).mean()\n",
    "    #     return torch.norm((y_pred-y), p=2, dim=1).mean()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00001, weight_decay=.3)\n",
    "    for t in range(100000):\n",
    "        for ix, (_x, _y) in enumerate(dl):\n",
    "            _x = Variable(_x).float()\n",
    "            _y = Variable(_y).float()\n",
    "\n",
    "            y_pred = model(_x)\n",
    "\n",
    "            loss = loss_fn(y_pred, _y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        y_pred = model(Variable(ds.X).float())\n",
    "        train_loss = loss_fn(y_pred, Variable(ds.y).float()).data.numpy()\n",
    "        losses[t] = train_loss\n",
    "        print(t,train_loss)\n",
    "\n",
    "        ave, map_ = evaluate(y_pred.data.numpy(),ds.y.data.numpy())\n",
    "        train_ave[t] = ave * 2000/X.shape[0]\n",
    "        train_map[t] = map_ * X.shape[0]/2000\n",
    "        y_pred_val = model(Variable(torch.from_numpy(X_val)).float())\n",
    "        ave_val, map_val = evaluate(y_pred_val.data.numpy(),y_val)\n",
    "        val_ave[t] = ave_val * 2000/X_val.shape[0]\n",
    "        val_map[t] = map_val * X_val.shape[0]/2000\n",
    "        n_epochs = t\n",
    "        print(\"\"\"Iter %d: Train Ave Rank: %g, Train MAP@20: %g,\n",
    "         Val Ave Rank: %g, Val MAP@20: %g\"\"\" % (t,train_ave[t],train_map[t],val_ave[t],val_map[t]))\n",
    "        \n",
    "        if t>=early_stop_window:\n",
    "            if val_map[t]<val_map[t-early_stop_window]:\n",
    "                print(\"EARLY STOP TRIGGERED BECAUSE NO IMPROVEMENT FOR %d ITERATIONS\" % (early_stop_window,))\n",
    "                return model, losses, train_ave, train_map, val_ave, val_map, n_epochs-early_stop_window\n",
    "\n",
    "#         if (t+1)%15==0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] /= 1.05\n",
    "    \n",
    "    return model, losses, train_ave, train_map, val_ave, val_map, n_epochs\n",
    "\n",
    "def predict(model,X):\n",
    "    return model(Variable(torch.from_numpy(X)).float()).data.numpy()\n",
    "\n",
    "def get_prediction(vecs,pics):\n",
    "    dists = pairwise_distances(vecs,pics,metric='cosine')\n",
    "    return dists.argsort(1)\n",
    "\n",
    "def map_20(ranks):\n",
    "    return np.mean([(20-rank)/20 if rank<20 else 0 for rank in ranks])\n",
    "\n",
    "def evaluate(vectors,label_vectors):\n",
    "    preds = get_prediction(vectors,label_vectors)\n",
    "    ranks = [np.argwhere(vec==i)[0][0] for i,vec in enumerate(preds)]\n",
    "    return np.mean(ranks),map_20(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pic_mats(n_components):\n",
    "    pics_train = np.load('pics_train_full.npy')\n",
    "    pics_test = np.load('pics_test_full.npy')\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(pics_train)\n",
    "    pics_train = pca.transform(pics_train)\n",
    "    pics_test = pca.transform(pics_test)\n",
    "    return pics_train, pics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ n_c=100, n_h=1024 ************\n",
      "0 0.98762804\n",
      "Iter 0: Train Ave Rank: 951.187, Train MAP@20: 0.00555,\n",
      "         Val Ave Rank: 954.666, Val MAP@20: 0.006075\n",
      "1 0.9780992\n",
      "Iter 1: Train Ave Rank: 920.949, Train MAP@20: 0.0062,\n",
      "         Val Ave Rank: 925.435, Val MAP@20: 0.00675\n",
      "2 0.9693056\n",
      "Iter 2: Train Ave Rank: 901.446, Train MAP@20: 0.00675,\n",
      "         Val Ave Rank: 905.915, Val MAP@20: 0.007225\n",
      "3 0.9601917\n",
      "Iter 3: Train Ave Rank: 886.559, Train MAP@20: 0.0075,\n",
      "         Val Ave Rank: 891.121, Val MAP@20: 0.007575\n",
      "4 0.9492116\n",
      "Iter 4: Train Ave Rank: 872.596, Train MAP@20: 0.008125,\n",
      "         Val Ave Rank: 876.976, Val MAP@20: 0.00835\n",
      "5 0.9337236\n",
      "Iter 5: Train Ave Rank: 853.795, Train MAP@20: 0.0099,\n",
      "         Val Ave Rank: 858.316, Val MAP@20: 0.00905\n",
      "6 0.9016691\n",
      "Iter 6: Train Ave Rank: 819.796, Train MAP@20: 0.01305,\n",
      "         Val Ave Rank: 825.316, Val MAP@20: 0.010525\n",
      "7 0.4695031\n",
      "Iter 7: Train Ave Rank: 140.881, Train MAP@20: 0.2092,\n",
      "         Val Ave Rank: 149.142, Val MAP@20: 0.14295\n",
      "8 0.26568085\n",
      "Iter 8: Train Ave Rank: 43.3325, Train MAP@20: 0.872875,\n",
      "         Val Ave Rank: 61.0315, Val MAP@20: 0.338125\n",
      "9 0.23116797\n",
      "Iter 9: Train Ave Rank: 27.2434, Train MAP@20: 1.29905,\n",
      "         Val Ave Rank: 47.9945, Val MAP@20: 0.3996\n",
      "10 0.21448416\n",
      "Iter 10: Train Ave Rank: 20.3647, Train MAP@20: 1.6098,\n",
      "         Val Ave Rank: 43.1945, Val MAP@20: 0.4294\n",
      "11 0.20209193\n",
      "Iter 11: Train Ave Rank: 16.1227, Train MAP@20: 1.85605,\n",
      "         Val Ave Rank: 40.4005, Val MAP@20: 0.442475\n",
      "12 0.19219935\n",
      "Iter 12: Train Ave Rank: 13.5944, Train MAP@20: 2.02107,\n",
      "         Val Ave Rank: 39.611, Val MAP@20: 0.453575\n",
      "13 0.18509728\n",
      "Iter 13: Train Ave Rank: 11.7843, Train MAP@20: 2.1854,\n",
      "         Val Ave Rank: 39.22, Val MAP@20: 0.45715\n",
      "14 0.17751616\n",
      "Iter 14: Train Ave Rank: 10.3305, Train MAP@20: 2.31645,\n",
      "         Val Ave Rank: 38.678, Val MAP@20: 0.461275\n",
      "15 0.17106563\n",
      "Iter 15: Train Ave Rank: 9.12556, Train MAP@20: 2.4441,\n",
      "         Val Ave Rank: 38.6955, Val MAP@20: 0.46565\n",
      "16 0.16646266\n",
      "Iter 16: Train Ave Rank: 8.23588, Train MAP@20: 2.5535,\n",
      "         Val Ave Rank: 38.9625, Val MAP@20: 0.46815\n",
      "17 0.16146237\n",
      "Iter 17: Train Ave Rank: 7.59203, Train MAP@20: 2.63417,\n",
      "         Val Ave Rank: 39.833, Val MAP@20: 0.463875\n",
      "18 0.15724546\n",
      "Iter 18: Train Ave Rank: 6.91025, Train MAP@20: 2.71095,\n",
      "         Val Ave Rank: 40.313, Val MAP@20: 0.46485\n",
      "19 0.15252924\n",
      "Iter 19: Train Ave Rank: 6.42563, Train MAP@20: 2.78055,\n",
      "         Val Ave Rank: 40.8605, Val MAP@20: 0.46715\n",
      "20 0.14944845\n",
      "Iter 20: Train Ave Rank: 5.87209, Train MAP@20: 2.84863,\n",
      "         Val Ave Rank: 41.0605, Val MAP@20: 0.462775\n",
      "EARLY STOP TRIGGERED BECAUSE NO IMPROVEMENT FOR 5 ITERATIONS\n",
      "0 0.98985785\n",
      "Iter 0: Train Ave Rank: 960.161, Train MAP@20: 0.00565,\n",
      "         Val Ave Rank: 961.808, Val MAP@20: 0.00645\n",
      "1 0.9805396\n",
      "Iter 1: Train Ave Rank: 931.017, Train MAP@20: 0.005575,\n",
      "         Val Ave Rank: 933.544, Val MAP@20: 0.006875\n",
      "2 0.9722952\n",
      "Iter 2: Train Ave Rank: 910.039, Train MAP@20: 0.005875,\n",
      "         Val Ave Rank: 912.901, Val MAP@20: 0.006825\n",
      "3 0.9641555\n",
      "Iter 3: Train Ave Rank: 894.339, Train MAP@20: 0.006,\n",
      "         Val Ave Rank: 897.211, Val MAP@20: 0.00715\n",
      "4 0.9552347\n",
      "Iter 4: Train Ave Rank: 881.127, Train MAP@20: 0.006075,\n",
      "         Val Ave Rank: 883.778, Val MAP@20: 0.007575\n",
      "5 0.9437251\n",
      "Iter 5: Train Ave Rank: 868.322, Train MAP@20: 0.006325,\n",
      "         Val Ave Rank: 870.868, Val MAP@20: 0.008225\n",
      "6 0.92368203\n",
      "Iter 6: Train Ave Rank: 845.881, Train MAP@20: 0.0072,\n",
      "         Val Ave Rank: 849.037, Val MAP@20: 0.008825\n",
      "7 0.854296\n",
      "Iter 7: Train Ave Rank: 756.321, Train MAP@20: 0.01185,\n",
      "         Val Ave Rank: 761.986, Val MAP@20: 0.012275\n",
      "8 0.3056566\n",
      "Iter 8: Train Ave Rank: 71.1125, Train MAP@20: 0.5699,\n",
      "         Val Ave Rank: 82.4705, Val MAP@20: 0.257375\n",
      "9 0.24592894\n",
      "Iter 9: Train Ave Rank: 34.6003, Train MAP@20: 1.11343,\n",
      "         Val Ave Rank: 52.7925, Val MAP@20: 0.36055\n",
      "10 0.2223165\n",
      "Iter 10: Train Ave Rank: 24.6317, Train MAP@20: 1.45215,\n",
      "         Val Ave Rank: 45.6545, Val MAP@20: 0.402925\n",
      "11 0.20856297\n",
      "Iter 11: Train Ave Rank: 19.037, Train MAP@20: 1.70442,\n",
      "         Val Ave Rank: 41.3095, Val MAP@20: 0.428625\n",
      "12 0.19712591\n",
      "Iter 12: Train Ave Rank: 15.6429, Train MAP@20: 1.90915,\n",
      "         Val Ave Rank: 39.2565, Val MAP@20: 0.440575\n",
      "13 0.18881518\n",
      "Iter 13: Train Ave Rank: 13.392, Train MAP@20: 2.06385,\n",
      "         Val Ave Rank: 38.457, Val MAP@20: 0.448225\n",
      "14 0.18103218\n",
      "Iter 14: Train Ave Rank: 11.5508, Train MAP@20: 2.21572,\n",
      "         Val Ave Rank: 38.312, Val MAP@20: 0.455775\n",
      "15 0.1755904\n",
      "Iter 15: Train Ave Rank: 10.1776, Train MAP@20: 2.34448,\n",
      "         Val Ave Rank: 37.8755, Val MAP@20: 0.46155\n",
      "16 0.17023122\n",
      "Iter 16: Train Ave Rank: 9.08291, Train MAP@20: 2.44215,\n",
      "         Val Ave Rank: 39.5625, Val MAP@20: 0.4614\n",
      "17 0.16599536\n",
      "Iter 17: Train Ave Rank: 8.089, Train MAP@20: 2.55762,\n",
      "         Val Ave Rank: 38.2255, Val MAP@20: 0.4661\n",
      "18 0.1606232\n",
      "Iter 18: Train Ave Rank: 7.35934, Train MAP@20: 2.64315,\n",
      "         Val Ave Rank: 40.1915, Val MAP@20: 0.4651\n",
      "19 0.15653765\n",
      "Iter 19: Train Ave Rank: 6.69487, Train MAP@20: 2.71907,\n",
      "         Val Ave Rank: 40.3565, Val MAP@20: 0.465075\n",
      "20 0.15261048\n",
      "Iter 20: Train Ave Rank: 6.29253, Train MAP@20: 2.78218,\n",
      "         Val Ave Rank: 41.089, Val MAP@20: 0.467275\n",
      "21 0.15015626\n",
      "Iter 21: Train Ave Rank: 5.633, Train MAP@20: 2.86253,\n",
      "         Val Ave Rank: 41.06, Val MAP@20: 0.468225\n",
      "22 0.14629316\n",
      "Iter 22: Train Ave Rank: 5.35122, Train MAP@20: 2.91215,\n",
      "         Val Ave Rank: 41.8575, Val MAP@20: 0.4696\n",
      "23 0.14246434\n",
      "Iter 23: Train Ave Rank: 4.94197, Train MAP@20: 2.9662,\n",
      "         Val Ave Rank: 42.7245, Val MAP@20: 0.46335\n",
      "EARLY STOP TRIGGERED BECAUSE NO IMPROVEMENT FOR 5 ITERATIONS\n",
      "0 0.98677284\n",
      "Iter 0: Train Ave Rank: 949.499, Train MAP@20: 0.005925,\n",
      "         Val Ave Rank: 950.337, Val MAP@20: 0.0058\n",
      "1 0.97614133\n",
      "Iter 1: Train Ave Rank: 908.424, Train MAP@20: 0.006775,\n",
      "         Val Ave Rank: 910.757, Val MAP@20: 0.00635\n",
      "2 0.96616095\n",
      "Iter 2: Train Ave Rank: 877.718, Train MAP@20: 0.007525,\n",
      "         Val Ave Rank: 880.942, Val MAP@20: 0.007325\n",
      "3 0.95553744\n",
      "Iter 3: Train Ave Rank: 851.81, Train MAP@20: 0.007725,\n",
      "         Val Ave Rank: 855.512, Val MAP@20: 0.0078\n",
      "4 0.9418293\n",
      "Iter 4: Train Ave Rank: 822.842, Train MAP@20: 0.008425,\n",
      "         Val Ave Rank: 827.017, Val MAP@20: 0.008325\n",
      "5 0.9174449\n",
      "Iter 5: Train Ave Rank: 784.972, Train MAP@20: 0.01,\n",
      "         Val Ave Rank: 788.938, Val MAP@20: 0.010075\n",
      "6 0.805164\n",
      "Iter 6: Train Ave Rank: 637.247, Train MAP@20: 0.027,\n",
      "         Val Ave Rank: 642.379, Val MAP@20: 0.02435\n",
      "7 0.28582197\n",
      "Iter 7: Train Ave Rank: 55.5693, Train MAP@20: 0.6945,\n",
      "         Val Ave Rank: 76.7975, Val MAP@20: 0.300875\n",
      "8 0.23985893\n",
      "Iter 8: Train Ave Rank: 30.2442, Train MAP@20: 1.19117,\n",
      "         Val Ave Rank: 54.2655, Val MAP@20: 0.380125\n",
      "9 0.21757019\n",
      "Iter 9: Train Ave Rank: 22.1088, Train MAP@20: 1.50525,\n",
      "         Val Ave Rank: 48.0885, Val MAP@20: 0.41465\n",
      "10 0.2046963\n",
      "Iter 10: Train Ave Rank: 17.2932, Train MAP@20: 1.75603,\n",
      "         Val Ave Rank: 44.7645, Val MAP@20: 0.4326\n",
      "11 0.19368798\n",
      "Iter 11: Train Ave Rank: 14.4023, Train MAP@20: 1.96125,\n",
      "         Val Ave Rank: 42.4725, Val MAP@20: 0.44345\n",
      "12 0.18459165\n",
      "Iter 12: Train Ave Rank: 12.463, Train MAP@20: 2.13858,\n",
      "         Val Ave Rank: 42.3365, Val MAP@20: 0.45185\n",
      "13 0.17738569\n",
      "Iter 13: Train Ave Rank: 10.632, Train MAP@20: 2.30088,\n",
      "         Val Ave Rank: 40.1325, Val MAP@20: 0.456225\n",
      "14 0.17095578\n",
      "Iter 14: Train Ave Rank: 9.61069, Train MAP@20: 2.4169,\n",
      "         Val Ave Rank: 41.021, Val MAP@20: 0.4607\n",
      "15 0.16605306\n",
      "Iter 15: Train Ave Rank: 8.54031, Train MAP@20: 2.52137,\n",
      "         Val Ave Rank: 41.137, Val MAP@20: 0.45955\n",
      "16 0.16127992\n",
      "Iter 16: Train Ave Rank: 7.75625, Train MAP@20: 2.6156,\n",
      "         Val Ave Rank: 41.6895, Val MAP@20: 0.461125\n",
      "17 0.15659744\n",
      "Iter 17: Train Ave Rank: 7.09756, Train MAP@20: 2.695,\n",
      "         Val Ave Rank: 43.1175, Val MAP@20: 0.45845\n",
      "18 0.1514588\n",
      "Iter 18: Train Ave Rank: 6.41191, Train MAP@20: 2.77592,\n",
      "         Val Ave Rank: 42.7265, Val MAP@20: 0.4548\n",
      "EARLY STOP TRIGGERED BECAUSE NO IMPROVEMENT FOR 5 ITERATIONS\n",
      "0 0.9798577\n",
      "Iter 0: Train Ave Rank: 956.918, Train MAP@20: 0.006075,\n",
      "         Val Ave Rank: 956.128, Val MAP@20: 0.0059\n",
      "1 0.97004944\n",
      "Iter 1: Train Ave Rank: 931.363, Train MAP@20: 0.006125,\n",
      "         Val Ave Rank: 931.934, Val MAP@20: 0.006375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.96127844\n",
      "Iter 2: Train Ave Rank: 914.399, Train MAP@20: 0.006525,\n",
      "         Val Ave Rank: 915.773, Val MAP@20: 0.00665\n",
      "3 0.9522704\n",
      "Iter 3: Train Ave Rank: 901.448, Train MAP@20: 0.00685,\n",
      "         Val Ave Rank: 903.578, Val MAP@20: 0.007175\n",
      "4 0.94184256\n",
      "Iter 4: Train Ave Rank: 889.186, Train MAP@20: 0.006825,\n",
      "         Val Ave Rank: 892.119, Val MAP@20: 0.00755\n",
      "5 0.9272547\n",
      "Iter 5: Train Ave Rank: 874.87, Train MAP@20: 0.007175,\n",
      "         Val Ave Rank: 878.59, Val MAP@20: 0.008075\n",
      "6 0.8987426\n",
      "Iter 6: Train Ave Rank: 844.585, Train MAP@20: 0.008925,\n",
      "         Val Ave Rank: 850.041, Val MAP@20: 0.00945\n",
      "7 0.71477306\n",
      "Iter 7: Train Ave Rank: 587.44, Train MAP@20: 0.035,\n",
      "         Val Ave Rank: 602.401, Val MAP@20: 0.0346\n",
      "8 0.28031492\n",
      "Iter 8: Train Ave Rank: 51.4485, Train MAP@20: 0.735975,\n",
      "         Val Ave Rank: 68.319, Val MAP@20: 0.306375\n",
      "9 0.2372706\n",
      "Iter 9: Train Ave Rank: 29.7291, Train MAP@20: 1.20625,\n",
      "         Val Ave Rank: 49.3485, Val MAP@20: 0.3879\n",
      "10 0.21855235\n",
      "Iter 10: Train Ave Rank: 21.4331, Train MAP@20: 1.54363,\n",
      "         Val Ave Rank: 41.7985, Val MAP@20: 0.425425\n",
      "11 0.20478666\n",
      "Iter 11: Train Ave Rank: 17.0735, Train MAP@20: 1.7656,\n",
      "         Val Ave Rank: 39.547, Val MAP@20: 0.4392\n",
      "12 0.19424611\n",
      "Iter 12: Train Ave Rank: 15.1923, Train MAP@20: 1.93235,\n",
      "         Val Ave Rank: 38.892, Val MAP@20: 0.446325\n",
      "13 0.185525\n",
      "Iter 13: Train Ave Rank: 12.3328, Train MAP@20: 2.13733,\n",
      "         Val Ave Rank: 36.509, Val MAP@20: 0.456575\n",
      "14 0.18032986\n",
      "Iter 14: Train Ave Rank: 10.8003, Train MAP@20: 2.2671,\n",
      "         Val Ave Rank: 37.4795, Val MAP@20: 0.457325\n",
      "15 0.1735996\n",
      "Iter 15: Train Ave Rank: 9.71031, Train MAP@20: 2.37668,\n",
      "         Val Ave Rank: 37.3605, Val MAP@20: 0.4591\n",
      "16 0.1694181\n",
      "Iter 16: Train Ave Rank: 9.11253, Train MAP@20: 2.46573,\n",
      "         Val Ave Rank: 38.6305, Val MAP@20: 0.459225\n",
      "17 0.16379106\n",
      "Iter 17: Train Ave Rank: 8.11372, Train MAP@20: 2.57023,\n",
      "         Val Ave Rank: 38.75, Val MAP@20: 0.462075\n",
      "18 0.15788078\n",
      "Iter 18: Train Ave Rank: 7.13197, Train MAP@20: 2.67557,\n",
      "         Val Ave Rank: 37.6135, Val MAP@20: 0.464175\n",
      "19 0.15476274\n",
      "Iter 19: Train Ave Rank: 6.42291, Train MAP@20: 2.77442,\n",
      "         Val Ave Rank: 38.37, Val MAP@20: 0.469225\n",
      "20 0.15086138\n",
      "Iter 20: Train Ave Rank: 6.23994, Train MAP@20: 2.80925,\n",
      "         Val Ave Rank: 39.5275, Val MAP@20: 0.462\n",
      "21 0.14819264\n",
      "Iter 21: Train Ave Rank: 5.78181, Train MAP@20: 2.86765,\n",
      "         Val Ave Rank: 41.1565, Val MAP@20: 0.461275\n",
      "22 0.14517063\n",
      "Iter 22: Train Ave Rank: 5.34903, Train MAP@20: 2.9276,\n",
      "         Val Ave Rank: 42.2555, Val MAP@20: 0.4589\n",
      "EARLY STOP TRIGGERED BECAUSE NO IMPROVEMENT FOR 5 ITERATIONS\n",
      "0 0.9808816\n",
      "Iter 0: Train Ave Rank: 955.643, Train MAP@20: 0.005675,\n",
      "         Val Ave Rank: 957.449, Val MAP@20: 0.0061\n",
      "1 0.97149575\n",
      "Iter 1: Train Ave Rank: 928.7, Train MAP@20: 0.006125,\n",
      "         Val Ave Rank: 932.668, Val MAP@20: 0.006575\n",
      "2 0.9630675\n",
      "Iter 2: Train Ave Rank: 910.014, Train MAP@20: 0.0068,\n",
      "         Val Ave Rank: 915.256, Val MAP@20: 0.00735\n",
      "3 0.9545391\n",
      "Iter 3: Train Ave Rank: 895.333, Train MAP@20: 0.0074,\n",
      "         Val Ave Rank: 901.787, Val MAP@20: 0.007875\n",
      "4 0.94468606\n",
      "Iter 4: Train Ave Rank: 882.816, Train MAP@20: 0.00775,\n",
      "         Val Ave Rank: 889.825, Val MAP@20: 0.008425\n",
      "5 0.93195367\n",
      "Iter 5: Train Ave Rank: 868.229, Train MAP@20: 0.00875,\n",
      "         Val Ave Rank: 876.212, Val MAP@20: 0.008275\n",
      "6 0.91105914\n",
      "Iter 6: Train Ave Rank: 846.321, Train MAP@20: 0.01085,\n",
      "         Val Ave Rank: 855.885, Val MAP@20: 0.008775\n",
      "7 0.8480515\n",
      "Iter 7: Train Ave Rank: 773.941, Train MAP@20: 0.01375,\n",
      "         Val Ave Rank: 788.51, Val MAP@20: 0.013525\n",
      "8 0.3253296\n",
      "Iter 8: Train Ave Rank: 83.6556, Train MAP@20: 0.479525,\n",
      "         Val Ave Rank: 98.1135, Val MAP@20: 0.235175\n",
      "9 0.2492373\n",
      "Iter 9: Train Ave Rank: 36.9147, Train MAP@20: 1.02687,\n",
      "         Val Ave Rank: 57.648, Val MAP@20: 0.366425\n",
      "10 0.22365242\n",
      "Iter 10: Train Ave Rank: 23.9927, Train MAP@20: 1.4091,\n",
      "         Val Ave Rank: 46.2055, Val MAP@20: 0.418425\n",
      "11 0.21117043\n",
      "Iter 11: Train Ave Rank: 19.2188, Train MAP@20: 1.63575,\n",
      "         Val Ave Rank: 43.4015, Val MAP@20: 0.436525\n",
      "12 0.19982976\n",
      "Iter 12: Train Ave Rank: 15.4017, Train MAP@20: 1.85567,\n",
      "         Val Ave Rank: 40.3325, Val MAP@20: 0.454775\n",
      "13 0.1885724\n",
      "Iter 13: Train Ave Rank: 12.998, Train MAP@20: 2.04625,\n",
      "         Val Ave Rank: 38.843, Val MAP@20: 0.468375\n",
      "14 0.18264472\n",
      "Iter 14: Train Ave Rank: 11.6335, Train MAP@20: 2.1725,\n",
      "         Val Ave Rank: 38.868, Val MAP@20: 0.466475\n",
      "15 0.17688352\n",
      "Iter 15: Train Ave Rank: 10.0945, Train MAP@20: 2.31218,\n",
      "         Val Ave Rank: 39.129, Val MAP@20: 0.47015\n",
      "16 0.1704045\n",
      "Iter 16: Train Ave Rank: 8.94444, Train MAP@20: 2.44985,\n",
      "         Val Ave Rank: 38.0835, Val MAP@20: 0.4812\n",
      "17 0.16582811\n",
      "Iter 17: Train Ave Rank: 8.1265, Train MAP@20: 2.53187,\n",
      "         Val Ave Rank: 39.3715, Val MAP@20: 0.4846\n",
      "18 0.16076988\n",
      "Iter 18: Train Ave Rank: 7.40294, Train MAP@20: 2.62147,\n",
      "         Val Ave Rank: 38.1165, Val MAP@20: 0.48475\n",
      "19 0.15644413\n",
      "Iter 19: Train Ave Rank: 6.81778, Train MAP@20: 2.69943,\n",
      "         Val Ave Rank: 39.777, Val MAP@20: 0.48065\n",
      "20 0.15188283\n",
      "Iter 20: Train Ave Rank: 6.15772, Train MAP@20: 2.7912,\n",
      "         Val Ave Rank: 40.3585, Val MAP@20: 0.488225\n",
      "21 0.1486668\n",
      "Iter 21: Train Ave Rank: 5.79672, Train MAP@20: 2.84472,\n",
      "         Val Ave Rank: 41.076, Val MAP@20: 0.487375\n",
      "22 0.14593732\n",
      "Iter 22: Train Ave Rank: 5.32347, Train MAP@20: 2.9044,\n",
      "         Val Ave Rank: 41.4585, Val MAP@20: 0.4833\n",
      "EARLY STOP TRIGGERED BECAUSE NO IMPROVEMENT FOR 5 ITERATIONS\n",
      "[15, 18, 13, 17, 17] 16.0\n",
      "[0.46814999999999996, 0.4614, 0.461125, 0.45922500000000005, 0.48120000000000007] 0.46622\n"
     ]
    }
   ],
   "source": [
    "n_components = [100]#[,300]#[30,100,300]\n",
    "n_hidden_units = [1024]#[2048,4096]\n",
    "# results = {}\n",
    "\n",
    "for n_c, n_h in itertools.product(n_components,n_hidden_units):\n",
    "    print(\"************ n_c=%d, n_h=%d ************\" % (n_c,n_h))\n",
    "    pics_train, _ = get_pic_mats(n_c)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=55)\n",
    "    n_epochs_results = []\n",
    "    val_map_results = []\n",
    "    for train_index,test_index in cv.split(text_train,pics_train):\n",
    "        rets = fit(text_train[train_index],pics_train[train_index],\n",
    "                   text_train[test_index],pics_train[test_index],5,n_h)\n",
    "        model, losses, train_ave, train_map, val_ave, val_map, n_epochs = rets\n",
    "        n_epochs_results.append(n_epochs)\n",
    "        val_map_results.append(val_map)\n",
    "    print(n_epochs_results,np.mean(n_epochs_results))\n",
    "    best_epoch = int(np.mean(n_epochs_results))\n",
    "    print([d[best_epoch] for d in val_map_results],np.mean([d[best_epoch] for d in val_map_results]))\n",
    "    results[(n_c, n_h)] = np.mean([d[best_epoch] for d in val_map_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41942500000000005"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([d[len(d)-1] for d in val_map_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(30, 1024): 0.43669,\n",
       " (30, 2048): 0.436705,\n",
       " (30, 4096): 0.436365,\n",
       " (100, 1024): 0.46622,\n",
       " (100, 2048): 0.4646450000000001,\n",
       " (100, 4096): 0.45801499999999995}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,y,n_epochs,H_1):\n",
    "    ds = PrepareData(X=X, y=y)\n",
    "    dl = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    D_in, D_out = X.shape[1], y.shape[1]\n",
    "    \n",
    "    model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H_1),\n",
    "#           torch.nn.Dropout(0.2),\n",
    "#           torch.nn.BatchNorm1d(H_1),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H_1, D_out),\n",
    "        ).to(device)\n",
    "    \n",
    "    def loss_fn(y_pred, y):\n",
    "        cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        return 1 - cos(y_pred, y).mean()\n",
    "    #     return torch.norm((y_pred-y), p=2, dim=1).mean()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00001*5/6, weight_decay=.3)\n",
    "    for t in range(n_epochs):\n",
    "        for ix, (_x, _y) in enumerate(dl):\n",
    "            _x = Variable(_x).float()\n",
    "            _y = Variable(_y).float()\n",
    "\n",
    "            y_pred = model(_x)\n",
    "\n",
    "            loss = loss_fn(y_pred, _y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        y_pred = model(Variable(ds.X).float())\n",
    "        train_loss = loss_fn(y_pred, Variable(ds.y).float()).data.numpy()\n",
    "        losses[t] = train_loss\n",
    "        print(t,train_loss)\n",
    "\n",
    "        ave, map_ = evaluate(y_pred.data.numpy(),ds.y.data.numpy())\n",
    "        ave = ave * 2000/X.shape[0]\n",
    "        map_ = map_ * X.shape[0]/2000\n",
    "        print(\"\"\"Iter %d: Train Ave Rank: %g, Train MAP@20: %g\"\"\" % (t,train_ave[t],train_map[t]))\n",
    "\n",
    "#         if (t+1)%15==0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] /= 1.05\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict(model,X):\n",
    "    return model(Variable(torch.from_numpy(X)).float()).data.numpy()\n",
    "\n",
    "def get_prediction(vecs,pics):\n",
    "    dists = pairwise_distances(vecs,pics,metric='cosine')\n",
    "    return dists.argsort(1)\n",
    "\n",
    "def map_20(ranks):\n",
    "    return np.mean([(20-rank)/20 if rank<20 else 0 for rank in ranks])\n",
    "\n",
    "def evaluate(vectors,label_vectors):\n",
    "    preds = get_prediction(vectors,label_vectors)\n",
    "    ranks = [np.argwhere(vec==i)[0][0] for i,vec in enumerate(preds)]\n",
    "    return np.mean(ranks),map_20(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train, pics_test = get_pic_mats(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 5510), (10000, 100))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train.shape,pics_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9829637\n",
      "Iter 0: Train Ave Rank: 955.643, Train MAP@20: 0.005675\n",
      "1 0.97357994\n",
      "Iter 1: Train Ave Rank: 928.7, Train MAP@20: 0.006125\n",
      "2 0.9654285\n",
      "Iter 2: Train Ave Rank: 910.014, Train MAP@20: 0.0068\n",
      "3 0.9573029\n",
      "Iter 3: Train Ave Rank: 895.333, Train MAP@20: 0.0074\n",
      "4 0.9484356\n",
      "Iter 4: Train Ave Rank: 882.816, Train MAP@20: 0.00775\n",
      "5 0.9372075\n",
      "Iter 5: Train Ave Rank: 868.229, Train MAP@20: 0.00875\n",
      "6 0.9200603\n",
      "Iter 6: Train Ave Rank: 846.321, Train MAP@20: 0.01085\n",
      "7 0.8745588\n",
      "Iter 7: Train Ave Rank: 773.941, Train MAP@20: 0.01375\n",
      "8 0.3563701\n",
      "Iter 8: Train Ave Rank: 83.6556, Train MAP@20: 0.479525\n",
      "9 0.26080847\n",
      "Iter 9: Train Ave Rank: 36.9147, Train MAP@20: 1.02687\n",
      "10 0.23464012\n",
      "Iter 10: Train Ave Rank: 23.9927, Train MAP@20: 1.4091\n",
      "11 0.22113079\n",
      "Iter 11: Train Ave Rank: 19.2188, Train MAP@20: 1.63575\n",
      "12 0.20989472\n",
      "Iter 12: Train Ave Rank: 15.4017, Train MAP@20: 1.85567\n",
      "13 0.20302242\n",
      "Iter 13: Train Ave Rank: 12.998, Train MAP@20: 2.04625\n",
      "14 0.19477022\n",
      "Iter 14: Train Ave Rank: 11.6335, Train MAP@20: 2.1725\n",
      "15 0.18870598\n",
      "Iter 15: Train Ave Rank: 10.0945, Train MAP@20: 2.31218\n"
     ]
    }
   ],
   "source": [
    "model = fit(text_train,pics_train,16,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vecs,pics):\n",
    "    dists = pairwise_distances(vecs,pics,metric='cosine')\n",
    "    return dists.argsort(1)\n",
    "\n",
    "def map_20(ranks):\n",
    "    return np.mean([(20-rank)/20 if rank<20 else 0 for rank in ranks])\n",
    "\n",
    "def evaluate(vectors,label_vectors):\n",
    "    preds = get_prediction(vectors,label_vectors)\n",
    "    ranks = [np.argwhere(vec==i)[0][0] for i,vec in enumerate(preds)]\n",
    "    return np.mean(ranks),map_20(ranks)\n",
    "\n",
    "def get_top_20(descr_id):\n",
    "    return preds[descr_id][:20]\n",
    "\n",
    "def save_submission():\n",
    "    data = []\n",
    "    for i in range(2000):\n",
    "        data.append(['%d.txt' % (i,),' '.join('%d.jpg' % (pic_id,) for pic_id in get_top_20(i))])\n",
    "    pd.DataFrame(data,columns=['Descritpion_ID','Top_20_Image_IDs']).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = predict(model,text_test)\n",
    "preds = get_prediction(vecs,pics_test)\n",
    "save_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 714, 1011, 1380, ...,  644, 1313, 1114])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
